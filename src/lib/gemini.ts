import { GoogleGenAI, ThinkingLevel, Type } from "@google/genai";

const getAI = () => {
  const storedKey = localStorage.getItem('GEMINI_API_KEY');
  let apiKey = storedKey || process.env.GEMINI_API_KEY;
  
  // Filter out the placeholder from .env.example
  if (apiKey === "MY_GEMINI_API_KEY") {
    apiKey = undefined;
  }

  if (!apiKey) {
    throw new Error("Ù…ÙØªØ§Ø­ Gemini API Ù…ÙÙ‚ÙˆØ¯. Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¥Ø¯Ø®Ø§Ù„Ù‡ ÙÙŠ ØµÙØ­Ø© Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª.");
  }
  
  const ai = new GoogleGenAI({ apiKey });
  
  // Wrap generateContent with automatic retry on network/rate limit errors
  const originalGenerateContent = ai.models.generateContent.bind(ai.models);
  ai.models.generateContent = async (...args: any[]) => {
    let lastError: any;
    for (let attempt = 0; attempt < 3; attempt++) {
      try {
        return await originalGenerateContent(...args);
      } catch (error: any) {
        lastError = error;
        if ((isNetworkError(error) || isRateLimitError(error)) && attempt < 2) {
          const delay = 2000 * Math.pow(2, attempt);
          console.warn(`Retry ${attempt + 1}/2 in ${delay}ms: ${error.message}`);
          await new Promise(r => setTimeout(r, delay));
          continue;
        }
        throw error;
      }
    }
    throw lastError;
  };
  
  return ai;
};

const isPermissionError = (error: any) => {
  return error.message?.includes('403') || error.status === 403 || error.message?.includes('PERMISSION_DENIED');
};

const isRateLimitError = (error: any) => {
  return error.message?.includes('429') || error.status === 429 || error.message?.includes('RESOURCE_EXHAUSTED');
};

const isNetworkError = (error: any) => {
  return error.message?.includes('Failed to fetch') || error.message?.includes('NetworkError') || error.message?.includes('network') || error.name === 'TypeError';
};

const withRetry = async <T>(fn: () => Promise<T>, maxRetries = 3, baseDelayMs = 2000): Promise<T> => {
  let attempt = 0;
  while (attempt < maxRetries) {
    try {
      return await fn();
    } catch (error: any) {
      const shouldRetry = isRateLimitError(error) || isNetworkError(error);
      if (shouldRetry && attempt < maxRetries - 1) {
        attempt++;
        const delay = baseDelayMs * Math.pow(2, attempt - 1);
        console.warn(`Retrying in ${delay}ms (attempt ${attempt}/${maxRetries - 1}): ${error.message}`);
        await new Promise(resolve => setTimeout(resolve, delay));
      } else {
        throw error;
      }
    }
  }
  throw new Error("Max retries reached");
};

const handleCommonErrors = (error: any, defaultMessage: string) => {
  if (isRateLimitError(error)) {
    throw new Error("Ù„Ù‚Ø¯ ØªØ¬Ø§ÙˆØ²Øª Ø§Ù„Ø­Ø¯ Ø§Ù„Ù…Ø³Ù…ÙˆØ­ Ø¨Ù‡ Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… (Rate Limit). ÙŠØ±Ø¬Ù‰ Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø± Ù‚Ù„ÙŠÙ„Ø§Ù‹ Ø«Ù… Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.");
  }
  if (isPermissionError(error)) {
    throw new Error("ØªÙ… Ø±ÙØ¶ Ø§Ù„ÙˆØµÙˆÙ„ (403). ØªØ£ÙƒØ¯ Ù…Ù† ØµÙ„Ø§Ø­ÙŠØ§Øª Ù…ÙØªØ§Ø­ API.");
  }
  if (isNetworkError(error)) {
    throw new Error("Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ø´Ø¨ÙƒØ©. ØªØ£ÙƒØ¯ Ù…Ù† Ø§ØªØµØ§Ù„Ùƒ Ø¨Ø§Ù„Ø¥Ù†ØªØ±Ù†Øª ÙˆØ­Ø§ÙˆÙ„ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.");
  }
  throw new Error(defaultMessage);
};

// Helper function to convert URL or data URL to base64
const imageToBase64 = async (imageSource: string): Promise<string> => {
  if (!imageSource || imageSource.length < 50) {
    console.warn("[v0] imageToBase64: Invalid image source, length:", imageSource?.length);
    return '';
  }
  
  console.log("[v0] imageToBase64 processing:", imageSource.substring(0, 80));
  
  // If it's already a data URL, extract base64
  if (imageSource.startsWith('data:')) {
    const matches = imageSource.match(/^data:[^;]+;base64,(.+)$/);
    if (matches) {
      console.log("[v0] Extracted base64 from data URL, length:", matches[1].length);
      return matches[1];
    }
    // If it has comma, split and return
    if (imageSource.includes(',')) {
      const base64 = imageSource.split(',')[1];
      console.log("[v0] Split base64 from data URL, length:", base64?.length);
      return base64 || '';
    }
  }
  
  // If it's a URL, fetch and convert using blob + FileReader for browser compatibility
  if (imageSource.startsWith('http://') || imageSource.startsWith('https://')) {
    try {
      console.log("[v0] Fetching image from URL...");
      const response = await fetch(imageSource);
      if (!response.ok) {
        console.warn(`[v0] Failed to fetch image: ${response.status}`);
        return '';
      }
      
      const blob = await response.blob();
      console.log("[v0] Fetched blob, size:", blob.size, "type:", blob.type);
      
      // Use FileReader for browser-safe base64 conversion
      return new Promise((resolve) => {
        const reader = new FileReader();
        reader.onloadend = () => {
          const dataUrl = reader.result as string;
          if (dataUrl && dataUrl.includes(',')) {
            const base64 = dataUrl.split(',')[1];
            console.log("[v0] Converted to base64, length:", base64?.length);
            resolve(base64 || '');
          } else {
            console.warn("[v0] FileReader returned invalid result");
            resolve('');
          }
        };
        reader.onerror = () => {
          console.warn("[v0] FileReader error");
          resolve('');
        };
        reader.readAsDataURL(blob);
      });
    } catch (e) {
      console.warn('[v0] Error fetching image:', e);
      return '';
    }
  }
  
  // Assume it's already base64
  console.log("[v0] Assuming raw base64, length:", imageSource.length);
  return imageSource;
};

const extractImage = (result: any) => {
  const candidate = result.candidates?.[0];
  if (!candidate) {
     // Check prompt feedback if available
     if (result.promptFeedback) {
        throw new Error(`Blocked by prompt feedback: ${JSON.stringify(result.promptFeedback)}`);
     }
     throw new Error("No candidates returned from Gemini");
  }
  
  const part = candidate.content?.parts?.find((p: any) => p.inlineData);
  if (part && part.inlineData && part.inlineData.data) {
    const dataUrl = `data:${part.inlineData.mimeType};base64,${part.inlineData.data}`;
    console.log(`Image extracted successfully. Size: ${Math.round(dataUrl.length / 1024)}KB`);
    return dataUrl;
  }
  
  // Check for text refusal/error
  const textPart = candidate.content?.parts?.find((p: any) => p.text);
  if (textPart?.text) {
    // If text is present, it might be a refusal or just a description.
    // We treat it as an error since we expected an image.
    throw new Error(`Model returned text instead of image: "${textPart.text.slice(0, 200)}..."`);
  }
  
  if (candidate.finishReason && candidate.finishReason !== 'STOP') {
      throw new Error(`Generation stopped with reason: ${candidate.finishReason}`);
  }

  throw new Error(`No image generated. Model response: ${JSON.stringify(candidate)}`);
};

export const GeminiService = {
  // Generate a story idea using AI
  async generateStoryIdea(charNames: string[], genre: string, hint?: string): Promise<string> {
    const ai = getAI();
    const result = await ai.models.generateContent({
      model: 'gemini-2.5-flash',
      contents: [{ role: 'user', parts: [{ text: `Ø£Ù†Øª ÙƒØ§ØªØ¨ Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ Ù…Ø­ØªØ±Ù. Ø§ÙƒØªØ¨ ÙÙƒØ±Ø© Ù‚ØµØ© Ù‚ØµÙŠØ±Ø© (3-4 Ø¬Ù…Ù„) Ù…Ù† Ù†ÙˆØ¹ "${genre}" ØªØªØ¶Ù…Ù† Ø§Ù„Ø´Ø®ØµÙŠØ§Øª Ø§Ù„ØªØ§Ù„ÙŠØ©: ${charNames.join(' Ùˆ ')}.
${hint ? `Ù…Ù„Ø§Ø­Ø¸Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: ${hint}` : ''}
Ø§ÙƒØªØ¨ Ø§Ù„ÙÙƒØ±Ø© Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙÙ‚Ø·. Ù„Ø§ ØªÙƒØªØ¨ Ø£ÙŠ Ø´ÙŠØ¡ Ø¢Ø®Ø± ØºÙŠØ± Ø§Ù„ÙÙƒØ±Ø©.` }] }],
    });
    return result.text?.trim() || '';
  },

  async testConnection(): Promise<boolean> {
    try {
      const ai = getAI();
      await ai.models.generateContent({
        model: "gemini-2.5-flash",
        contents: "Test"
      });
      return true;
    } catch (error: any) {
      console.error("Test connection failed:", error);
      if (isPermissionError(error)) {
        throw new Error("ØªÙ… Ø±ÙØ¶ Ø§Ù„ÙˆØµÙˆÙ„ (403). ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ù…ÙØªØ§Ø­ API ØµØ­ÙŠØ­ØŒ ÙˆØ£Ù† Ù…Ø´Ø±ÙˆØ¹ Google Cloud Ù…Ø±ØªØ¨Ø· Ø¨Ø­Ø³Ø§Ø¨ ÙÙˆØªØ±Ø© (Billing Account) ÙˆÙ…ÙØ¹Ù„ Ø¹Ù„ÙŠÙ‡ Generative Language API.");
      }
      throw error;
    }
  },

  // 1. Analyze Character Traits (Thinking Mode)
  async analyzeCharacter(imageBase64: string): Promise<string> {
    try {
      const ai = getAI();
      const prompt = `
        Analyze this character image in extreme detail for the purpose of creating a consistent character profile for animation.
        Focus on:
        1. Physical features (hair style/color, eye shape/color, face structure, body type).
        2. Clothing details (style, colors, specific items, textures).
        3. Distinctive accessories or markings.
        4. Overall art style (e.g., pixar-style, anime, realistic, watercolor).
        
        Provide a concise but comprehensive visual description that can be used as a prompt to recreate this character.
        Output in Arabic.
      `;

      // Strip header if present
      const base64Data = imageBase64.includes(',') ? imageBase64.split(',')[1] : imageBase64;

      const result = await ai.models.generateContent({
        model: "gemini-3.1-pro-preview",
        contents: [
          {
            role: "user",
            parts: [
              { text: prompt },
              { inlineData: { mimeType: "image/png", data: base64Data } }
            ]
          }
        ],
        config: {
          thinkingConfig: { thinkingLevel: ThinkingLevel.HIGH },
        }
      });

      return result.text || "";
    } catch (error: any) {
      if (isPermissionError(error)) {
        throw new Error("ÙØ´Ù„ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø´Ø®ØµÙŠØ© (403). ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„Ù…ÙØªØ§Ø­ Ø§Ù„Ø¹Ø§Ù… Ù„Ø¯ÙŠÙ‡ ØµÙ„Ø§Ø­ÙŠØ© Ø§Ù„ÙˆØµÙˆÙ„ Ù„Ù†Ù…ÙˆØ°Ø¬ gemini-3.1-pro-preview.");
      }
      throw error;
    }
  },

  // 2. Generate Character Angles (Nano Banana 3 Pro)
  async generateCharacterAngle(description: string, angle: 'front' | 'left side' | 'right side' | '3/4 view'): Promise<string> {
    const ai = getAI();
    const prompt = `
      Generate a character image based on this description:
      ${description}
      
      View Angle: ${angle}
      Background: Neutral white or transparent.
      Style: Consistent character design sheet.
    `;

    try {
      const result = await ai.models.generateContent({
        model: "gemini-3-pro-image-preview",
        contents: [{ role: "user", parts: [{ text: prompt }] }],
        config: {
          imageConfig: { imageSize: "1K" }
        }
      });
      return extractImage(result);
    } catch (error: any) {
      if (isPermissionError(error)) {
        throw new Error("ÙØ´Ù„ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ±Ø© (403). ØªØ£ÙƒØ¯ Ù…Ù† ØµÙ„Ø§Ø­ÙŠØ§Øª Ù…ÙØªØ§Ø­ API Ù„Ù†Ù…ÙˆØ°Ø¬ gemini-3-pro-image-preview.");
      }
      throw error;
    }
  },

  // 3. Generate Script & Scenes (Thinking Mode)
  async generateScriptAndScenes(idea: string, characters: {name: string, description: string, visualTraits?: string}[]): Promise<{script: string, scenes: {description: string, characters: string[], dialogue: string}[]}> {
    try {
      const ai = getAI();
      const charContext = characters.map(c => `- ${c.name}: ${c.description}${c.visualTraits ? `. Ø§Ù„Ù…Ø¸Ù‡Ø±: ${c.visualTraits}` : ''}`).join("\n");
      const prompt = `Ø£Ù†Øª Ù…Ø®Ø±Ø¬ Ø£ÙÙ„Ø§Ù… ÙˆÙ…ØµÙˆØ± Ø³ÙŠÙ†Ù…Ø§Ø¦ÙŠ Ù…Ø­ØªØ±Ù. Ø£Ù†Ø´Ø¦ Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ Ù‚ØµÙŠØ± Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù‡Ø°Ù‡ Ø§Ù„ÙÙƒØ±Ø©: "${idea}".

Ø§Ù„Ø´Ø®ØµÙŠØ§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©:
${charContext}

Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ù…Ù‡Ù…Ø© - ÙÙƒØ± ÙƒÙ…Ø®Ø±Ø¬ Ø³ÙŠÙ†Ù…Ø§Ø¦ÙŠ ÙŠØ®Ø·Ø· Ù„Ù„Ù‚Ø·Ø§Øª Ù…ØªØªØ§Ù„ÙŠØ©:

âš¡ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø§Ø³ØªÙ…Ø±Ø§Ø±ÙŠØ©: ÙƒÙ„ Ù…Ø´Ù‡Ø¯ Ù…Ø¯ØªÙ‡ 8 Ø«ÙˆØ§Ù†Ù. Ø§Ù„Ù…Ø´Ø§Ù‡Ø¯ Ù‡ÙŠ Ù„Ù‚Ø·Ø§Øª Ù…ØªØªØ§Ù„ÙŠØ© Ù…ØªØµÙ„Ø© Ù…Ø«Ù„ ÙÙŠÙ„Ù… Ø­Ù‚ÙŠÙ‚ÙŠ.
- Ø§Ù„Ù…Ø´Ù‡Ø¯ Ø§Ù„Ø«Ø§Ù†ÙŠ ÙŠØ¨Ø¯Ø£ Ù…Ù† Ø­ÙŠØ« Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„Ø£ÙˆÙ„ Ø¨Ø§Ù„Ø¶Ø¨Ø·
- Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ø´Ø®ØµÙŠØ© ØªÙ…Ø´ÙŠ Ù†Ø­Ùˆ Ø§Ù„ÙŠÙ…ÙŠÙ† ÙÙŠ Ø§Ù„Ù…Ø´Ù‡Ø¯ 1ØŒ ÙŠØ¬Ø¨ Ø£Ù† ØªÙƒÙˆÙ† Ø£Ù‚Ø±Ø¨ Ù„Ù„ÙŠÙ…ÙŠÙ† ÙÙŠ Ø§Ù„Ù…Ø´Ù‡Ø¯ 2
- Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§ ØªÙ†ØªÙ‚Ù„ Ø¨Ø³Ù„Ø§Ø³Ø© Ø¨ÙŠÙ† Ø§Ù„Ù„Ù‚Ø·Ø§Øª (Ù…Ø«Ù„Ø§Ù‹: Ù„Ù‚Ø·Ø© ÙˆØ§ï¿½ï¿½Ø¹Ø© â† Ù…ØªÙˆØ³Ø·Ø© â† Ù‚Ø±ÙŠØ¨Ø© â† ÙÙˆÙ‚ Ø§Ù„ÙƒØªÙ)

âš¡ ÙˆØµÙ Ø§Ù„Ø­Ø±ÙƒØ©: Ù„ÙƒÙ„ Ù…Ø´Ù‡Ø¯ Ø§Ø°ÙƒØ±:
- Ù…Ø§Ø°Ø§ ØªÙØ¹Ù„ Ø§Ù„Ø´Ø®ØµÙŠØ© Ø¨Ø§Ù„Ø¶Ø¨Ø· (ØªÙ…Ø´ÙŠØŒ ØªÙ„ØªÙØªØŒ ØªØ¬Ù„Ø³ØŒ ØªØ´ÙŠØ± Ø¨ÙŠØ¯Ù‡Ø§)
- Ù…Ù† Ø£ÙŠ Ø§ØªØ¬Ø§Ù‡ ØªØ£ØªÙŠ/ØªØ°Ù‡Ø¨ Ø§Ù„Ø´Ø®ØµÙŠØ©
- ÙˆØ¶Ø¹ÙŠØ© Ø§Ù„Ø¬Ø³Ù… (ÙˆØ§Ù‚ÙØŒ Ø¬Ø§Ù„Ø³ØŒ Ù…Ù†Ø­Ù†ÙØŒ ÙŠØ±ÙƒØ¶)
- ØªØ¹Ø¨ÙŠØ± Ø§Ù„ÙˆØ¬Ù‡ (Ø§Ø¨ØªØ³Ø§Ù…Ø©ØŒ Ø¯Ù‡Ø´Ø©ØŒ ØªØ±ÙƒÙŠØ²ØŒ Ø­Ø²Ù†)

âš¡ ÙˆØµÙ Ø§Ù„Ù…ÙƒØ§Ù†: ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† Ø§Ù„Ù…ÙƒØ§Ù† ÙˆØ§Ø­Ø¯Ø§Ù‹ ÙˆÙ…ØªØ³Ù‚Ø§Ù‹:
- Ø§Ù„Ù…Ø´Ù‡Ø¯ Ø§Ù„Ø£ÙˆÙ„ ÙŠØ­Ø¯Ø¯ Ø§Ù„Ù…ÙƒØ§Ù† Ø¨Ø§Ù„ØªÙØµÙŠÙ„ (Ù‡Ùˆ Ø§Ù„Ù…Ø±Ø¬Ø¹ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ)
- Ø§Ù„Ù…Ø´Ø§Ù‡Ø¯ Ø§Ù„Ù„Ø§Ø­Ù‚Ø© ØªØµÙ Ù†ÙØ³ Ø§Ù„Ù…ÙƒØ§Ù† Ù…Ù† Ø²ÙˆØ§ÙŠØ§ Ù…Ø®ØªÙ„ÙØ©
- Ø§Ø°ÙƒØ± Ø§Ù„Ø¹Ù†Ø§ØµØ± Ø§Ù„Ù…Ø´ØªØ±ÙƒØ© (Ø´Ø¬Ø±Ø© Ù…Ø¹ÙŠÙ†Ø©ØŒ Ù…Ø¨Ù†Ù‰ØŒ Ù„ÙˆÙ† Ø§Ù„Ø³Ù…Ø§Ø¡) ÙÙŠ ÙƒÙ„ Ù…Ø´Ù‡Ø¯

âš¡ ØªØ®Ø·ÙŠØ· Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§: Ø®Ø·Ø· Ø§Ù„Ù„Ù‚Ø·Ø§Øª Ù…Ø«Ù„ Ù…Ø®Ø±Ø¬ Ù…Ø­ØªØ±Ù:
- Establishing Shot (Ù„Ù‚Ø·Ø© ØªØ£Ø³ÙŠØ³ÙŠØ© ÙˆØ§Ø³Ø¹Ø©) â†’ Medium Shot â†’ Close-up â†’ Over-the-shoulder â†’ Wide reaction shot
- Ù„Ø§ ØªÙ‚ÙØ² Ø¨ÙŠÙ† Ù„Ù‚Ø·ØªÙŠÙ† Ø¨Ø¹ÙŠØ¯ØªÙŠÙ† - Ø§Ø¬Ø¹Ù„ Ø§Ù„Ø§Ù†ØªÙ‚Ø§Ù„ Ø³Ù„Ø³Ø§Ù‹

Ù…Ø«Ø§Ù„ Ù„Ù…Ø´Ø§Ù‡Ø¯ Ù…ØªØªØ§Ù„ÙŠØ©:
Ø§Ù„Ù…Ø´Ù‡Ø¯ 1: "Wide establishing shot of a lush green park with tall pine trees. Golden afternoon sunlight filters through the leaves. Jad (brown short hair, blue t-shirt, jeans) walks from the LEFT side toward the center of the frame along a stone path. His expression is curious, looking around. Camera is static, positioned 10 meters away."
Ø§Ù„Ù…Ø´Ù‡Ø¯ 2: "Medium shot, same park, same lighting. Camera has moved closer. Jad (same outfit) has now reached the center of the path and STOPS, looking toward the RIGHT side of frame with a surprised smile. Behind him, the same pine trees visible. Camera at waist level, 3 meters away."
Ø§Ù„Ù…Ø´Ù‡Ø¯ 3: "Over-the-shoulder shot from behind Yazan's head (black curly hair, red hoodie). We see the same park path ahead, and Jad (blue t-shirt) standing 5 meters away, waving. Same golden light, same trees. Yazan is raising his right hand to wave back."

Ø§Ø°ÙƒØ± Ø§Ø³Ù… ÙƒÙ„ Ø´Ø®ØµÙŠØ© ÙˆÙ…Ø¸Ù‡Ø±Ù‡Ø§ Ø§Ù„ÙƒØ§Ù…Ù„ ÙÙŠ ÙƒÙ„ Ù…Ø´Ù‡Ø¯.

Ø£Ø®Ø±Ø¬ JSON:
1. "script": Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ Ø§Ù„ÙƒØ§Ù…Ù„ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
2. "scenes": Ù…ØµÙÙˆÙØ© Ù…Ù† Ø§Ù„Ù…Ø´Ø§Ù‡Ø¯ØŒ ÙƒÙ„ Ù…Ø´Ù‡Ø¯ ÙŠØ­ØªÙˆÙŠ:
   - "description": ÙˆØµÙ Ø¨ØµØ±ÙŠ Ø³ÙŠÙ†Ù…Ø§Ø¦ÙŠ Ù…ÙØµÙ„ Ø¬Ø¯Ø§Ù‹ Ø¨Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© (Ù„Ù„ØªÙˆÙ„ÙŠØ¯). ÙŠØ¬Ø¨ Ø£Ù† ÙŠØªØ¶Ù…Ù†: Ù†ÙˆØ¹ Ø§Ù„Ù„Ù‚Ø·Ø©ØŒ Ø§Ù„Ù…Ø³Ø§ÙØ©ØŒ Ø²Ø§ÙˆÙŠØ© Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§ØŒ Ø­Ø±ÙƒØ© Ø§Ù„Ø´Ø®ØµÙŠØ§ØªØŒ Ø§Ù„Ø§ØªØ¬Ø§Ù‡Ø§ØªØŒ ØªØ¹Ø§Ø¨ÙŠØ± Ø§Ù„ÙˆØ¬Ù‡ØŒ Ø§Ù„Ù…Ù„Ø§Ø¨Ø³ØŒ ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø®Ù„ÙÙŠØ©
   - "characters": Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø´Ø®ØµÙŠØ§Øª ÙÙŠ Ø§Ù„Ù…Ø´Ù‡Ø¯
   - "dialogue": Ø§Ù„Ø­ÙˆØ§Ø± Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© (ÙØ§Ø±Øº Ø¥Ù† Ù„Ù… ÙŠÙˆØ¬Ø¯)`;

      const result = await ai.models.generateContent({
        model: "gemini-3-flash",
        contents: [{ role: "user", parts: [{ text: prompt }] }],
        config: {
          responseMimeType: "application/json",
          responseSchema: {
            type: Type.OBJECT,
            properties: {
              script: { type: Type.STRING },
              scenes: {
                type: Type.ARRAY,
                items: {
                  type: Type.OBJECT,
                  properties: {
                    description: { type: Type.STRING },
                    characters: { type: Type.ARRAY, items: { type: Type.STRING } },
                    dialogue: { type: Type.STRING }
                  }
                }
              }
            }
          }
        }
      });

      const text = result.text || "{}";
      const jsonString = text.replace(/```json\n?|\n?```/g, "").trim();
      return JSON.parse(jsonString);
    } catch (error: any) {
      if (isPermissionError(error)) {
        throw new Error("ÙØ´Ù„ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ (403). ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„Ù…ÙØªØ§Ø­ Ù„Ø¯ÙŠÙ‡ ØµÙ„Ø§Ø­ÙŠØ© Ø§Ù„ÙˆØµÙˆÙ„ Ù„Ù†Ù…ÙˆØ°Ø¬ gemini-3-flash.");
      }
      throw error;
    }
  },

  // 4. Generate Storyboard Frame - Director Strategy with character consistency
  async generateStoryboardFrame(params: {
    sceneDescription: string;
    characterImages: string[];
    firstSceneImage?: string;
    previousSceneImage?: string;
    sceneIndex: number;
    totalScenes: number;
    style: string;
    aspectRatio: '16:9' | '9:16' | '1:1';
    characterDNA: string;
  }): Promise<string> {
    const ai = getAI();
    const { sceneDescription, characterImages, firstSceneImage, previousSceneImage, sceneIndex, totalScenes, style, aspectRatio, characterDNA } = params;
    
    const parts: any[] = [];
    
    console.log("[v0] generateStoryboardFrame called:");
    console.log("[v0] - characterImages count:", characterImages.length);
    console.log("[v0] - sceneIndex:", sceneIndex);
    console.log("[v0] - characterDNA:", characterDNA?.substring(0, 100));
    
    // === DIRECTOR STRATEGY: Think like a film director ===
    
    // STEP 1: CHARACTER REFERENCE IMAGES (HIGHEST PRIORITY - MANDATORY)
    // These are the "actors" - they must look EXACTLY the same in every scene
    if (characterImages.length > 0) {
      parts.push({ text: `ğŸ¬ CHARACTER CASTING SHEET - MANDATORY REFERENCE:
These are your ACTORS. You MUST copy their EXACT appearance in every detail:
- Face structure, eyes, nose, mouth - IDENTICAL
- Hair style, color, texture - IDENTICAL  
- Skin tone - IDENTICAL
- Clothing, accessories - IDENTICAL
- Body proportions - IDENTICAL

DO NOT create new characters. These actors MUST appear exactly as shown:` });
      
      const convertedImages = await Promise.all(
        characterImages.slice(0, 3).map(img => imageToBase64(img))
      );
      
      let validImagesCount = 0;
      for (let i = 0; i < convertedImages.length; i++) {
        const base64Data = convertedImages[i];
        console.log(`[v0] Character image ${i + 1} base64 length:`, base64Data?.length || 0);
        if (base64Data && base64Data.length > 100) {
          parts.push({ inlineData: { mimeType: 'image/jpeg', data: base64Data } });
          validImagesCount++;
        }
      }
      
      console.log("[v0] Valid character images added to prompt:", validImagesCount);
      if (validImagesCount === 0) {
        console.warn("[v0] WARNING: No valid character images could be converted!");
      }
    } else {
      console.warn("[v0] WARNING: No character images provided to generateStoryboardFrame!");
    }

    // STEP 2: SCENE 1 AS MASTER REFERENCE (for scenes 2+)
    // Scene 1 establishes the visual world - all other scenes must match
    if (sceneIndex > 0 && firstSceneImage) {
      parts.push({ text: `\nğŸ¥ MASTER REFERENCE - SCENE 1 (Establishing Shot):
This is the visual foundation of the story. Match these elements EXACTLY:
- Art style and rendering technique
- Color grading and palette
- Lighting mood and direction
- Environment design and atmosphere
- Character proportions and style` });
      
      const firstData = await imageToBase64(firstSceneImage);
      if (firstData && firstData.length > 100) {
        parts.push({ inlineData: { mimeType: 'image/jpeg', data: firstData } });
      }
    }
    
    // STEP 3: PREVIOUS SCENE FOR CONTINUITY (for scenes 2+)
    if (sceneIndex > 0 && previousSceneImage && previousSceneImage !== firstSceneImage) {
      parts.push({ text: `\nğŸï¸ PREVIOUS SCENE (Scene ${sceneIndex}) - Direct Continuity:
Continue the action from this frame. Maintain:
- Same location/environment (unless script says otherwise)
- Consistent character positions and poses
- Matching lighting and time of day
- Visual flow and narrative connection` });
      
      const prevData = await imageToBase64(previousSceneImage);
      if (prevData && prevData.length > 100) {
        parts.push({ inlineData: { mimeType: 'image/jpeg', data: prevData } });
      }
    }

    // STEP 4: DIRECTOR'S BRIEF - The actual scene to generate
    const directorBrief = `
ğŸ¬ DIRECTOR'S BRIEF - SCENE ${sceneIndex + 1} OF ${totalScenes}
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“‹ CHARACTER DNA (Who appears in this scene):
${characterDNA || 'Use the character reference images above.'}

ğŸ¯ SCENE ACTION:
${sceneDescription}

ğŸ¨ VISUAL STYLE: ${style}

ğŸ“ COMPOSITION (Think like a cinematographer):
- Frame the shot to emphasize the story moment
- Use appropriate camera angle (wide/medium/close-up based on emotion)
- Consider depth of field and focal points
- Lighting should match the mood

âš ï¸ CRITICAL RULES:
1. Characters MUST be PIXEL-PERFECT copies of the reference images above
2. DO NOT redesign, reimagine, or stylize the characters differently
3. ${sceneIndex === 0 
    ? 'ESTABLISHING SHOT: Define the world clearly - this becomes the reference for all future scenes' 
    : 'CONTINUITY: Must visually connect to the previous scene(s) shown above'}
4. Think like a film director - every element serves the story
5. Maintain consistent proportions, lighting, and atmosphere

Generate this cinematic frame now.`;

    parts.push({ text: directorBrief });

    try {
      const result = await ai.models.generateContent({
        model: "gemini-3-pro-image-preview",
        contents: [{ role: "user", parts }],
        config: {
          responseModalities: ["image", "text"],
          imageConfig: { aspectRatio }
        }
      });
      return extractImage(result);
    } catch (error: any) {
      if (isPermissionError(error)) {
        throw new Error("ÙØ´Ù„ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ø´Ù‡Ø¯ (403). ØªØ£ÙƒØ¯ Ù…Ù† ØµÙ„Ø§Ø­ÙŠØ§Øª Ù…ÙØªØ§Ø­ API.");
      }
      throw error;
    }
  },

  // 5. Generate Video Clip (Veo3)
  async generateVideoClip(startFrame: string, endFrame: string, aspectRatio: '16:9' | '9:16' = '16:9', cameraMotion?: string): Promise<string> {
    try {
      const ai = getAI();
      
      // Helper function to convert URL or data URL to base64
      const toBase64 = async (imageSource: string): Promise<{ base64: string; mimeType: string }> => {
        // If it's already a data URL
        if (imageSource.startsWith('data:')) {
          const matches = imageSource.match(/^data:([^;]+);base64,(.+)$/);
          if (matches) {
            return { base64: matches[2], mimeType: matches[1] };
          }
        }
        
        // If it's a URL, fetch and convert
        if (imageSource.startsWith('http://') || imageSource.startsWith('https://')) {
          const response = await fetch(imageSource);
          if (!response.ok) {
            throw new Error(`Failed to fetch image: ${response.status}`);
          }
          const blob = await response.blob();
          const mimeType = blob.type || 'image/png';
          
          return new Promise((resolve, reject) => {
            const reader = new FileReader();
            reader.onloadend = () => {
              const result = reader.result as string;
              const base64 = result.split(',')[1];
              resolve({ base64, mimeType });
            };
            reader.onerror = reject;
            reader.readAsDataURL(blob);
          });
        }
        
        // Assume it's already base64
        return { base64: imageSource, mimeType: 'image/png' };
      };
      
      const startData = await toBase64(startFrame);
      const endData = await toBase64(endFrame);

      let operation = await ai.models.generateVideos({
        model: 'veo-3.1-fast-generate-preview',
        prompt: cameraMotion ? `Camera motion: ${cameraMotion}` : undefined,
        image: {
          imageBytes: startData.base64,
          mimeType: startData.mimeType,
        },
        config: {
          numberOfVideos: 1,
          resolution: '720p',
          aspectRatio: aspectRatio,
          lastFrame: {
            imageBytes: endData.base64,
            mimeType: endData.mimeType
          }
        }
      });

      // Poll for completion
      while (!operation.done) {
        await new Promise(resolve => setTimeout(resolve, 5000));
        operation = await ai.operations.getVideosOperation({operation: operation});
      }

      const videoUri = operation.response?.generatedVideos?.[0]?.video?.uri;
      if (!videoUri) throw new Error("Video generation failed");

      // Fetch the actual video blob
      const storedKey = localStorage.getItem('GEMINI_API_KEY');
      const apiKey = storedKey || process.env.GEMINI_API_KEY!;

      const response = await fetch(videoUri, {
          headers: {
              'x-goog-api-key': apiKey
          }
      });
      
      const blob = await response.blob();
      // Convert to Base64 Data URL for persistence
      return new Promise((resolve, reject) => {
        const reader = new FileReader();
        reader.onloadend = () => resolve(reader.result as string);
        reader.onerror = reject;
        reader.readAsDataURL(blob);
      });
    } catch (error: any) {
      console.error("[v0] Video generation error:", error);
      
      if (isRateLimitError(error)) handleCommonErrors(error, "");
      if (isPermissionError(error)) {
        throw new Error("ÙØ´Ù„ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ (403). Ù†Ù…ÙˆØ°Ø¬ veo-3.1-fast-generate-preview ÙŠØªØ·Ù„Ø¨ Ù…Ø´Ø±ÙˆØ¹ Google Cloud Ù…Ø¯ÙÙˆØ¹ (Paid Billing). ØªØ£ÙƒØ¯ Ù…Ù† ØªÙØ¹ÙŠÙ„ Ø§Ù„ÙÙˆØªØ±Ø© Ùˆ Generative Language API.");
      }
      if (error?.message?.includes('not found') || error?.message?.includes('NOT_FOUND')) {
        throw new Error("Ù†Ù…ÙˆØ°Ø¬ veo-3.1-fast-generate-preview ØºÙŠØ± Ù…ï¿½ï¿½Ø§Ø­. ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ù…Ø´Ø±ÙˆØ¹Ùƒ ÙŠØ¯Ø¹Ù… Ù†Ù…Ø§Ø°Ø¬ Veo.");
      }
      if (error?.message?.includes('Failed to fetch image')) {
        throw new Error("ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©. ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† ØµÙˆØ± Ø§Ù„Ù…Ø´Ø§Ù‡Ø¯ Ù…Ø­ÙÙˆØ¸Ø© Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­.");
      }
      if (error?.message?.includes('CORS') || error?.message?.includes('cross-origin')) {
        throw new Error("Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø¨Ø³Ø¨Ø¨ Ù‚ÙŠÙˆØ¯ CORS. Ø­Ø§ÙˆÙ„ Ø¥Ø¹Ø§Ø¯Ø© ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ±.");
      }
      throw new Error(`ÙØ´Ù„ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ: ${error?.message || 'Ø®Ø·Ø£ ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ'}`);
    }
  },

  // 6. Generate Voiceover (TTS)
  async generateVoiceover(text: string, voiceName: string = 'Zephyr'): Promise<string> {
    try {
      const ai = getAI();
      const response = await ai.models.generateContent({
        model: "gemini-2.5-flash-preview-tts",
        contents: [{ parts: [{ text }] }],
        config: {
          responseModalities: ["AUDIO"],
          speechConfig: {
            voiceConfig: {
              prebuiltVoiceConfig: { voiceName }
            }
          }
        }
      });

      const base64Audio = response.candidates?.[0]?.content?.parts?.[0]?.inlineData?.data;
      if (!base64Audio) throw new Error("No audio generated");
      
      return `data:audio/wav;base64,${base64Audio}`;
    } catch (error: any) {
      console.error("TTS Error:", error);
      if (isPermissionError(error)) {
        throw new Error("ÙØ´Ù„ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØª (403). ØªØ£ÙƒØ¯ Ù…Ù† ØµÙ„Ø§Ø­ÙŠØ§Øª Ø§Ù„Ù…ÙØªØ§Ø­ Ù„Ù†Ù…ÙˆØ°Ø¬ TTS.");
      }
      throw new Error("ÙØ´Ù„ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØª.");
    }
  },

  // 7. Generate Surreal Object (Faceless Trend)
  async generateSurrealObject(params: {
    objectName: string;
    emotion: string;
    style: string;
    body: string;
    limbs: string;
    hair: string;
    cameraAngle: string;
    lighting: string;
    environment: string;
    generateNormal?: boolean;
  }): Promise<{ surreal: string; normal?: string }> {
    const ai = getAI();
    
    const surrealPrompt = `A highly detailed, hyper-realistic shot of an anthropomorphic ${params.objectName} character. 
    CRITICAL INSTRUCTION: The character's face MUST be made ENTIRELY out of the natural material, color, and texture of a ${params.objectName}. DO NOT paste a realistic human face or human skin onto it. The facial features (eyes, nose, mouth) should look like they organically grew, morphed, or were carved directly from the ${params.objectName}'s surface.
    Expression: ${params.emotion}. 
    Body type: ${params.body}. 
    Limbs/Hands: ${params.limbs}. 
    Hair/Top: ${params.hair}. 
    Camera Angle: ${params.cameraAngle}. 
    Lighting: ${params.lighting}. 
    Environment/Background: ${params.environment}. 
    Style: ${params.style}, 8k resolution, cinematic.`;

    const normalPrompt = `A highly detailed, hyper-realistic shot of a normal, everyday ${params.objectName}. 
    CRITICAL INSTRUCTION: This is a regular, inanimate object. DO NOT add any face, eyes, mouth, or human features whatsoever. It must look like a completely normal, natural ${params.objectName}.
    Camera Angle: ${params.cameraAngle}. 
    Lighting: ${params.lighting}. 
    Environment/Background: ${params.environment}. 
    Style: ${params.style}, 8k resolution, cinematic.`;

    const generateImage = async (promptText: string) => {
      try {
        const result = await ai.models.generateContent({
          model: "gemini-3-pro-image-preview",
          contents: [{ role: "user", parts: [{ text: promptText }] }],
          config: { 
            imageConfig: { aspectRatio: "3:4" },
          }
        });
        return extractImage(result);
      } catch (error: any) {
        if (isRateLimitError(error)) {
          handleCommonErrors(error, "");
        }
        if (isPermissionError(error)) {
          throw new Error("ÙØ´Ù„ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ±Ø© (403). ØªØ£ÙƒØ¯ Ù…Ù† ØµÙ„Ø§Ø­ÙŠØ§Øª Ù…ÙØªØ§Ø­ API Ù„Ù†Ù…ÙˆØ°Ø¬ gemini-3-pro-image-preview.");
        }
        handleCommonErrors(error, "ÙØ´Ù„ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ±Ø©.");
        throw error;
      }
    };

    try {
      if (params.generateNormal) {
        const [surreal, normal] = await Promise.all([
          generateImage(surrealPrompt),
          generateImage(normalPrompt)
        ]);
        return { surreal, normal };
      } else {
        const surreal = await generateImage(surrealPrompt);
        return { surreal };
      }
    } catch (error: any) {
      console.error("Surreal Generation Error:", error);
      handleCommonErrors(error, "ÙØ´Ù„ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ±Ø©. Ø­Ø§ÙˆÙ„ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.");
      throw error;
    }
  },

  // 7.5 Generate Creature Character
  async generateCreatureCharacter(params: {
    baseCreature: string;
    hybridCreature: string;
    bodyType: string;
    outfit: string;
    accessories: string;
    expression: string;
    style: string;
    background: string;
  }): Promise<string> {
    const ai = getAI();
    const prompt = `Create a highly detailed, professional character design of a creature.
    Base Creature: ${params.baseCreature}
    ${params.hybridCreature ? `Hybrid merged with: ${params.hybridCreature}` : ''}
    Body Type: ${params.bodyType}
    Outfit/Clothing: ${params.outfit}
    Accessories: ${params.accessories}
    Facial Expression: ${params.expression}
    Art Style: ${params.style}
    Background: ${params.background}
    
    CRITICAL INSTRUCTIONS:
    - The character must be the central focus, fully visible.
    - If Body Type is Humanoid, the creature should stand on two legs with human-like anatomy but keeping the creature's head, fur/scales, and tail/wings.
    - High quality, 8k resolution, masterpiece.
    - Aspect ratio MUST be 1:1.`;

    try {
      const result = await ai.models.generateContent({
        model: "gemini-3-pro-image-preview",
        contents: [{ role: "user", parts: [{ text: prompt }] }],
        config: { imageConfig: { aspectRatio: "1:1" } }
      });
      return extractImage(result);
    } catch (error: any) {
      if (isRateLimitError(error)) {
        handleCommonErrors(error, "");
      }
      if (isPermissionError(error)) {
        throw new Error("ÙØ´Ù„ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ±Ø© (403). ØªØ£ÙƒØ¯ Ù…Ù† ØµÙ„Ø§Ø­ÙŠØ§Øª Ù…ÙØªØ§Ø­ API Ù„Ù†Ù…ÙˆØ°Ø¬ gemini-3-pro-image-preview.");
      }
      handleCommonErrors(error, "ÙØ´Ù„ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ±Ø©.");
      throw error;
    }
  },

  // 7.7 Generate Hybrid Character
  async generateCharacter(prompt: string): Promise<any> {
    const ai = getAI();
    
    try {
      // 1. Generate the character profile and name using text model
      const textResult = await ai.models.generateContent({
        model: "gemini-3.1-pro-preview",
        contents: [{ role: "user", parts: [{ text: `${prompt}\n\nOutput a JSON object with exactly these keys: "name" (a creative Arabic name), "description" (a short Arabic backstory/description).` }] }],
        config: {
          responseMimeType: "application/json",
          responseSchema: {
            type: Type.OBJECT,
            properties: {
              name: { type: Type.STRING },
              description: { type: Type.STRING }
            }
          }
        }
      });

      const text = textResult.text || "{}";
      const jsonString = text.replace(/```json\n?|\n?```/g, "").trim();
      const profile = JSON.parse(jsonString);

      // 2. Generate the front view image using image model
      const imagePrompt = `${prompt}\n\nGenerate a character design sheet showing the front view. Neutral background. High quality, 8k resolution, masterpiece. Aspect ratio MUST be 1:1.`;
      
      const imageResult = await ai.models.generateContent({
        model: "gemini-3-pro-image-preview",
        contents: [{ role: "user", parts: [{ text: imagePrompt }] }],
        config: { imageConfig: { aspectRatio: "1:1" } }
      });
      
      const frontImage = extractImage(imageResult);

      return {
        name: profile.name || "Ø´Ø®ØµÙŠØ© Ù‡Ø¬ÙŠÙ†Ø©",
        description: profile.description || "Ø´Ø®ØµÙŠØ© ØºØ§Ù…Ø¶Ø© ØªÙ… Ø¯Ù…Ø¬Ù‡Ø§ Ù…Ù† Ù…ÙˆØ§Ø¯ Ù…Ø®ØªÙ„ÙØ©.",
        front: frontImage,
        side: frontImage, // Fallback
        back: frontImage  // Fallback
      };

    } catch (error: any) {
      if (isRateLimitError(error)) {
        handleCommonErrors(error, "");
      }
      if (isPermissionError(error)) {
        throw new Error("ÙØ´Ù„ Ø§Ù„ØªÙˆÙ„ÙŠØ¯ (403). ØªØ£ÙƒØ¯ Ù…Ù† ØµÙ„Ø§Ø­ÙŠØ§Øª Ù…ÙØªØ§Ø­ API.");
      }
      handleCommonErrors(error, "ÙØ´Ù„ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø´Ø®ØµÙŠØ© Ø§Ù„Ù‡Ø¬ÙŠÙ†Ø©.");
      throw error;
    }
  },

  // 7.6 Generate Viral Short Idea
  async generateViralShortIdea(params: { niche: string; tone: string; topic: string; characters?: string; sceneCount?: number }): Promise<any> {
    const ai = getAI();
    const prompt = `You are an expert YouTube Shorts and TikTok viral content strategist.
    Create a highly engaging, viral short video script (15-60 seconds) in Arabic.
    Niche: ${params.niche}
    Tone: ${params.tone}
    Specific Topic: ${params.topic || 'Surprise me with a trending topic in this niche'}
    ${params.characters ? `Characters to include: ${params.characters}` : ''}
    ${params.sceneCount ? `Number of scenes: Exactly ${params.sceneCount} scenes.` : ''}
    
    Output MUST be a valid JSON object with the following structure:
    {
      "title": "Catchy Video Title in Arabic",
      "hook": "The first 3 seconds hook to grab attention immediately (Arabic)",
      "visualConcept": "Brief description of what the viewer sees (Arabic)",
      "script": [
        {"time": "0:00-0:03", "visual": "...", "audio": "..."}
      ],
      "cta": "Call to action at the end (Arabic)",
      "tags": ["tag1", "tag2", "tag3"]
    }`;

    try {
      const result = await ai.models.generateContent({
        model: "gemini-3.1-pro-preview",
        contents: [{ role: "user", parts: [{ text: prompt }] }],
        config: {
          responseMimeType: "application/json",
          responseSchema: {
            type: Type.OBJECT,
            properties: {
              title: { type: Type.STRING },
              hook: { type: Type.STRING },
              visualConcept: { type: Type.STRING },
              script: {
                type: Type.ARRAY,
                items: {
                  type: Type.OBJECT,
                  properties: {
                    time: { type: Type.STRING },
                    visual: { type: Type.STRING },
                    audio: { type: Type.STRING }
                  }
                }
              },
              cta: { type: Type.STRING },
              tags: { type: Type.ARRAY, items: { type: Type.STRING } }
            }
          }
        }
      });
      const text = result.text || "{}";
      const jsonString = text.replace(/```json\n?|\n?```/g, "").trim();
      return JSON.parse(jsonString);
    } catch (error: any) {
      if (isRateLimitError(error)) handleCommonErrors(error, "");
      if (isPermissionError(error)) throw new Error("ÙØ´Ù„ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ÙÙƒØ±Ø© (403). ØªØ£ÙƒØ¯ Ù…Ù† ØµÙ„Ø§Ø­ÙŠØ§Øª Ø§Ù„Ù…ÙØªØ§Ø­.");
      handleCommonErrors(error, "ÙØ´Ù„ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ÙÙƒØ±Ø©.");
      throw error;
    }
  },

  // 8. Auto-Generate Surreal Idea
  async generateRandomSurrealIdea(userPrompt?: string): Promise<any> {
    const ai = getAI();
    const prompt = `
      You are a creative director for a viral "faceless" YouTube Shorts channel.
      Generate a bizarre, surreal, and highly engaging anthropomorphic character idea.
      ${userPrompt ? `Base it loosely on this idea: "${userPrompt}"` : 'Make it completely random and unexpected (e.g., a crying piece of toast, an angry black hole, a disgusted sock).'}
      
      Output a JSON object with EXACTLY these keys (values must be strings in English, except where noted):
      - objectName: (e.g., "Toast", "Black Hole", "Sock")
      - emotion: (e.g., "Crying", "Angry", "Shocked", "Creepy", "Smiling")
      - style: (e.g., "Hyperrealistic", "Claymation", "3D Render", "Cinematic")
      - body: (e.g., "No body (face only)", "Tiny body", "Muscular", "Stick figure")
      - limbs: (e.g., "No limbs", "Cartoon arms", "Roots")
      - hair: (e.g., "Bald", "Grass", "Fire", "Smoke")
      - cameraAngle: "Ø²Ø§ÙˆÙŠØ© Ø£Ù…Ø§Ù…ÙŠØ© Ù…Ø¨Ø§Ø´Ø±Ø© (Front-facing)"
      - lighting: (e.g., "Cinematic dramatic", "Bright studio")
      - environment: "Ø®Ù„ÙÙŠØ© Ø¨ÙŠØ¶Ø§Ø¡ Ù†Ù‚ÙŠØ© (Pure White)"
    `;

    try {
      const result = await ai.models.generateContent({
        model: "gemini-3.1-pro-preview",
        contents: [{ role: "user", parts: [{ text: prompt }] }],
        config: {
          responseMimeType: "application/json",
          responseSchema: {
            type: Type.OBJECT,
            properties: {
              objectName: { type: Type.STRING },
              emotion: { type: Type.STRING },
              style: { type: Type.STRING },
              body: { type: Type.STRING },
              limbs: { type: Type.STRING },
              hair: { type: Type.STRING },
              cameraAngle: { type: Type.STRING },
              lighting: { type: Type.STRING },
              environment: { type: Type.STRING }
            }
          }
        }
      });

      const text = result.text || "{}";
      const jsonString = text.replace(/```json\n?|\n?```/g, "").trim();
      return JSON.parse(jsonString);
    } catch (error: any) {
      console.error("Auto-generate error:", error);
      throw new Error("ÙØ´Ù„ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ÙÙƒØ±Ø© Ø§Ù„Ø¹Ø´ÙˆØ§Ø¦ÙŠØ©.");
    }
  },

  // 9. Generate Human Character
  async generateHumanCharacter(params: {
    gender: string;
    age: string;
    ethnicity: string;
    hair: string;
    eyeColor: string;
    bodyType: string;
    clothing: string;
    expression: string;
    style: string;
    environment: string;
    cameraAngle: string;
  }): Promise<string> {
    const ai = getAI();
    const prompt = `A highly detailed, hyper-realistic portrait of a human character.
    The following features are described in Arabic, please understand them and generate the corresponding image:
    Gender: ${params.gender}.
    Age: ${params.age}.
    Ethnicity/Skin Tone: ${params.ethnicity}.
    Hair: ${params.hair}.
    Eye Color: ${params.eyeColor}.
    Body Type: ${params.bodyType}.
    Clothing: ${params.clothing}.
    Expression: ${params.expression}.
    Camera Angle: ${params.cameraAngle}.
    Environment/Background: ${params.environment}.
    Style: ${params.style}.
    
    CRITICAL INSTRUCTION: You MUST generate an image. Do not output text. 8k resolution, highly detailed, cinematic lighting.`;

    try {
      const result = await ai.models.generateContent({
        model: "gemini-3-pro-image-preview",
        contents: [{ role: "user", parts: [{ text: prompt }] }],
        config: { imageConfig: { aspectRatio: "3:4" } }
      });
      return extractImage(result);
    } catch (error: any) {
      if (isRateLimitError(error)) {
        handleCommonErrors(error, "");
      }
      if (isPermissionError(error)) {
        throw new Error("ÙØ´Ù„ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ±Ø© (403). ØªØ£ÙƒØ¯ Ù…Ù† ØµÙ„Ø§Ø­ÙŠØ§Øª Ù…ÙØªØ§Ø­ API Ù„Ù†Ù…ÙˆØ°Ø¬ gemini-3-pro-image-preview.");
      }
      handleCommonErrors(error, "ÙØ´Ù„ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ±Ø©.");
      throw error;
    }
  },

  // 10. Auto-Generate Human Idea
  async generateRandomHumanIdea(): Promise<any> {
    const ai = getAI();
    const prompt = `
      You are an expert character designer. Generate a unique, interesting, and highly detailed human character concept.
      Output a JSON object with EXACTLY these keys (values MUST be strings in Arabic):
      - gender: (e.g., "Ø°ÙƒØ±", "Ø£Ù†Ø«Ù‰")
      - age: (e.g., "Ø´Ø§Ø¨ ÙÙŠ Ø§Ù„Ø¹Ø´Ø±ÙŠÙ†Ø§Øª", "Ø±Ø¬Ù„ Ø¹Ø¬ÙˆØ² ÙÙŠ Ø§Ù„Ø³Ø¨Ø¹ÙŠÙ†Ø§Øª", "Ù…Ø±Ø§Ù‡Ù‚Ø©", "Ø·ÙÙ„")
      - ethnicity: (e.g., "Ø¹Ø±Ø¨ÙŠ Ø£Ø³Ù…Ø±", "Ø¢Ø³ÙŠÙˆÙŠ", "Ø£ÙˆØ±ÙˆØ¨ÙŠ Ø£Ø´Ù‚Ø±", "Ø£ÙØ±ÙŠÙ‚ÙŠ", "Ø­Ù†Ø·ÙŠ Ø§Ù„Ø¨Ø´Ø±Ø©")
      - hair: (e.g., "Ø´Ø¹Ø± Ø£Ø³ÙˆØ¯ Ù‚ØµÙŠØ± ÙˆÙ…Ø¬Ø¹Ø¯", "Ø´Ø¹Ø± Ø£Ø´Ù‚Ø± Ø·ÙˆÙŠÙ„ ÙˆÙ…Ù…ÙˆØ¬", "Ø£ØµÙ„Ø¹ Ù…Ø¹ Ù„Ø­ÙŠØ© ÙƒØ«ÙŠÙØ©", "ØªØ³Ø±ÙŠØ­Ø© Ø°ÙŠÙ„ Ø­ØµØ§Ù†")
      - eyeColor: (e.g., "Ø¨Ù†ÙŠ ØºØ§Ù…Ù‚", "Ø£Ø²Ø±Ù‚ ÙØ§ØªØ­", "Ø£Ø®Ø¶Ø± Ø²Ù…Ø±Ø¯ÙŠ", "Ø¹Ø³Ù„ÙŠ")
      - bodyType: (e.g., "Ø±ÙŠØ§Ø¶ÙŠ Ù…ÙØªÙˆÙ„ Ø§Ù„Ø¹Ø¶Ù„Ø§Øª", "Ù†Ø­ÙŠÙ", "Ù…ØªÙˆØ³Ø· Ø§Ù„Ø¨Ù†ÙŠØ©", "Ù…Ù…ØªÙ„Ø¦")
      - clothing: (e.g., "Ù…Ù„Ø§Ø¨Ø³ Ø³Ø§ÙŠØ¨Ø±Ø¨Ø§Ù†Ùƒ Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠØ© Ù…Ø¶ÙŠØ¦Ø©", "Ø¨Ø¯Ù„Ø© Ø±Ø³Ù…ÙŠØ© Ø£Ù†ÙŠÙ‚Ø©", "Ù…Ù„Ø§Ø¨Ø³ ÙƒØ§Ø¬ÙˆØ§Ù„ ÙŠÙˆÙ…ÙŠØ©", "Ø¯Ø±Ø¹ ÙØ§Ø±Ø³ Ù…Ù† Ø§Ù„ï¿½ï¿½ØµÙˆØ± Ø§Ù„ÙˆØ³Ø·Ù‰", "Ù…Ù„Ø§Ø¨Ø³ Ù†ÙŠÙ†Ø¬Ø§")
      - expression: (e.g., "Ù†Ø¸Ø±Ø© Ø­Ø§Ø¯Ø© ÙˆÙˆØ§Ø«Ù‚Ø©", "Ø§Ø¨ØªØ³Ø§Ù…Ø© Ù„Ø·ÙŠÙØ©", "Ù…Ù„Ø§Ù…Ø­ ØºØ§Ø¶Ø¨Ø© ÙˆØ¬Ø§Ø¯Ø©", "Ù†Ø¸Ø±ï¿½ï¿½ Ø­Ø²ÙŠÙ†Ø©")
      - style: (e.g., "ÙˆØ§Ù‚Ø¹ÙŠ Ø¬Ø¯Ø§Ù‹ (Hyperrealistic)", "Ø£Ù†Ù…ÙŠ (Anime)", "Ø¨ÙŠÙƒØ³Ø§Ø± 3D (Pixar 3D)", "Ø³ÙŠÙ†Ù…Ø§Ø¦ÙŠ (Cinematic)")
      - environment: (e.g., "Ø´Ø§Ø±Ø¹ Ù…Ø¯ÙŠÙ†Ø© Ù…Ù…Ø·Ø± Ù„ÙŠÙ„Ø§Ù‹", "Ø®Ù„ÙÙŠØ© Ø§Ø³ØªÙˆØ¯ÙŠÙˆ Ø±Ù…Ø§Ø¯ÙŠØ©", "ØºØ§Ø¨Ø© Ù…Ø´Ù…Ø³Ø©", "Ù…Ù‚Ù‡Ù‰ ÙƒÙ„Ø§Ø³ÙŠÙƒÙŠ")
      - cameraAngle: (e.g., "Ù„Ù‚Ø·Ø© Ù‚Ø±ÙŠØ¨Ø© Ù„Ù„ÙˆØ¬Ù‡ (Close-up)", "Ù„Ù‚Ø·Ø© Ù…ØªÙˆØ³Ø·Ø© (Medium shot)", "Ù„Ù‚Ø·Ø© ÙƒØ§Ù…Ù„Ø© Ù„Ù„Ø¬Ø³Ù… (Full body)")
    `;

    try {
      const result = await ai.models.generateContent({
        model: "gemini-3.1-pro-preview",
        contents: [{ role: "user", parts: [{ text: prompt }] }],
        config: {
          responseMimeType: "application/json",
          responseSchema: {
            type: Type.OBJECT,
            properties: {
              gender: { type: Type.STRING },
              age: { type: Type.STRING },
              ethnicity: { type: Type.STRING },
              hair: { type: Type.STRING },
              eyeColor: { type: Type.STRING },
              bodyType: { type: Type.STRING },
              clothing: { type: Type.STRING },
              expression: { type: Type.STRING },
              style: { type: Type.STRING },
              environment: { type: Type.STRING },
              cameraAngle: { type: Type.STRING }
            }
          }
        }
      });

      const text = result.text || "{}";
      const jsonString = text.replace(/```json\n?|\n?```/g, "").trim();
      return JSON.parse(jsonString);
    } catch (error: any) {
      console.error("Auto-generate error:", error);
      throw new Error("ÙØ´Ù„ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ÙÙƒØ±Ø© Ø§Ù„Ø¹Ø´ÙˆØ§Ø¦ÙŠØ©.");
    }
  },

  // 11. Generate Funny Human
  async generateFunnyHuman(params: {
    baseHuman: string;
    mergedWith: string;
    crazyFeature: string;
    expression: string;
    style: string;
    environment: string;
  }): Promise<string> {
    const ai = getAI();
    const prompt = `A highly detailed, hilarious, and bizarre surreal image.
    The following features are described in Arabic, please understand them and generate the corresponding image:
    Base Human Subject: ${params.baseHuman}.
    Merged or combined with: ${params.mergedWith}.
    Crazy feature/mutation: ${params.crazyFeature}.
    Expression: ${params.expression}.
    Environment/Background: ${params.environment}.
    Style: ${params.style}.
    
    CRITICAL INSTRUCTION: You MUST generate an image. Do not output text. Make it look extremely convincing but conceptually absurd, funny, and weird. 8k resolution, highly detailed.`;

    try {
      const result = await ai.models.generateContent({
        model: "gemini-3-pro-image-preview",
        contents: [{ role: "user", parts: [{ text: prompt }] }],
        config: { imageConfig: { aspectRatio: "3:4" } }
      });
      return extractImage(result);
    } catch (error: any) {
      if (isRateLimitError(error)) {
        handleCommonErrors(error, "");
      }
      if (isPermissionError(error)) {
        throw new Error("ÙØ´Ù„ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ±Ø© (403). ØªØ£ÙƒØ¯ Ù…Ù† ØµÙ„Ø§Ø­ÙŠØ§Øª Ù…ÙØªØ§Ø­ API Ù„Ù†Ù…ÙˆØ°Ø¬ gemini-3-pro-image-preview.");
      }
      handleCommonErrors(error, "ÙØ´Ù„ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ±Ø©.");
      throw error;
    }
  },

  // 12. Auto-Generate Funny Human Idea
  async generateRandomFunnyHumanIdea(): Promise<any> {
    const ai = getAI();
    const prompt = `
      You are a comedy genius and character designer. Generate a hilarious, bizarre, and unexpected human-hybrid character concept.
      Output a JSON object with EXACTLY these keys (values MUST be strings in Arabic):
      - baseHuman: (e.g., "Ø±Ø¬Ù„ Ø£Ø¹Ù…Ø§Ù„ Ø¬Ø§Ø¯", "Ø¬Ø¯Ø© Ù„Ø·ÙŠÙØ©", "Ø¹Ø§Ù…Ù„ Ø¨Ù†Ø§Ø¡", "Ø·Ø¨ÙŠØ¨ Ø¬Ø±Ø§Ø­")
      - mergedWith: (e.g., "ØºØ³Ø§Ù„Ø© Ù…Ù„Ø§Ø¨Ø³", "Ø£Ø·Ø±Ø§Ù Ø£Ø®Ø·Ø¨ÙˆØ·", "Ø¹Ø¬Ù„Ø§Øª Ø³ÙŠØ§Ø±Ø©", "Ø¬Ø³Ù… Ø«Ù„Ø§Ø¬Ø©", "Ø£Ø¬Ù†Ø­Ø© Ø¯Ø¬Ø§Ø¬Ø© Ù…Ù‚Ù„ÙŠØ©")
      - crazyFeature: (e.g., "Ø±Ø£Ø³ Ø¹Ù…Ù„Ø§Ù‚ ÙˆØ¬Ø³Ù… ØµØºÙŠØ±", "Ø¹ÙŠÙˆÙ† ÙÙŠ Ø§Ù„ÙŠØ¯ÙŠÙ†", "Ø£Ù†Ù Ø¹Ù„Ù‰ Ø´ÙƒÙ„ ÙÙŠÙ„", "Ø±Ù‚Ø¨Ø© Ø²Ø±Ø§ÙØ©")
      - expression: (e.g., "ÙŠØ¶Ø­Ùƒ Ø¨Ù‡Ø³ØªÙŠØ±ÙŠØ§", "Ù†Ø¸Ø±Ø© Ù…ÙŠØªØ© (Deadpan)", "Ù…ØµØ¯ÙˆÙ… Ø¬Ø¯Ø§Ù‹", "ÙŠØ¨ÙƒÙŠ Ù…Ù† Ø§Ù„Ø¶Ø­Ùƒ")
      - style: (e.g., "ØµÙˆØ±Ø© ÙÙˆØªÙˆØºØ±Ø§ÙÙŠØ© ÙˆØ§Ù‚Ø¹ÙŠØ©", "ÙƒØ§Ù…ÙŠØ±Ø§ Ù…Ø±Ø§Ù‚Ø¨Ø© (CCTV)", "Ø±Ø³ÙˆÙ… Ù…ØªØ­Ø±ÙƒØ© 3D", "ØµÙˆØ±Ø© Ø¨ÙˆÙ„Ø§Ø±ÙˆÙŠØ¯ Ù‚Ø¯ÙŠÙ…Ø©")
      - environment: (e.g., "Ø³ÙˆØ¨Ø± Ù…Ø§Ø±ÙƒØª", "Ø§Ø¬ØªÙ…Ø§Ø¹ Ø¹Ù…Ù„ Ø±Ø³Ù…ÙŠ", "Ø§Ù„ÙØ¶Ø§Ø¡ Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠ", "Ø­Ù…Ø§Ù… Ø³Ø¨Ø§Ø­Ø©")
    `;

    try {
      const result = await ai.models.generateContent({
        model: "gemini-3.1-pro-preview",
        contents: [{ role: "user", parts: [{ text: prompt }] }],
        config: {
          responseMimeType: "application/json",
          responseSchema: {
            type: Type.OBJECT,
            properties: {
              baseHuman: { type: Type.STRING },
              mergedWith: { type: Type.STRING },
              crazyFeature: { type: Type.STRING },
              expression: { type: Type.STRING },
              style: { type: Type.STRING },
              environment: { type: Type.STRING }
            }
          }
        }
      });

      const text = result.text || "{}";
      const jsonString = text.replace(/```json\n?|\n?```/g, "").trim();
      return JSON.parse(jsonString);
    } catch (error: any) {
      console.error("Auto-generate error:", error);
      throw new Error("ÙØ´Ù„ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ÙÙƒØ±Ø© Ø§Ù„Ø¹Ø´ÙˆØ§Ø¦ÙŠØ©.");
    }
  },

  // 13. Generate YouTube Thumbnail
  async generateThumbnail(params: {
    title: string;
    style: string;
    elements: string;
    background: string;
    referenceImages?: { name: string; dataUrl: string }[];
    elementImages?: { name: string; dataUrl: string }[];
    baseThumbnail?: string;
    imageText?: string;
    // New parameters
    facialExpression?: string;
    eyeExpression?: string;
    headShape?: string;
    bodyShape?: string;
    eyeColor?: string;
    emotion?: string;
    bodyPose?: string;
    channelNiche?: string;
    videoType?: string;
    brandColors?: string;
    aspectRatio?: string;
  }): Promise<string> {
    const ai = getAI();
    
    // Parse aspect ratio
    let parsedAspectRatio: "16:9" | "9:16" | "1:1" | "3:4" | "4:3" | "any" = "16:9";
    if (params.aspectRatio) {
      if (params.aspectRatio.includes("16:9")) parsedAspectRatio = "16:9";
      else if (params.aspectRatio.includes("9:16")) parsedAspectRatio = "9:16";
      else if (params.aspectRatio.includes("1:1")) parsedAspectRatio = "1:1";
      else if (params.aspectRatio.includes("4:3")) parsedAspectRatio = "4:3";
    }

    let prompt = "";
    if (params.baseThumbnail) {
      prompt = `You are an expert YouTube thumbnail designer. I have provided a base thumbnail image. Your task is to ENHANCE, REMIX, and UPGRADE it to make it highly professional, clickbaity, and viral.
      Style/Vibe: ${params.style}.
      ${params.elements ? `Add these elements: ${params.elements}.` : ''}
      ${params.brandColors ? `Use these brand colors prominently: ${params.brandColors}.` : ''}
      
      CRITICAL INSTRUCTIONS:
      - Aspect ratio MUST be ${parsedAspectRatio}.
      - Upgrade the lighting to cinematic 8k resolution, vibrant colors, and high contrast.
      - If reference characters are provided, REPLACE the main person/subject in the base thumbnail with the provided reference character. Match the lighting and perspective seamlessly.
      ${params.imageText ? `- REPLACE any existing text in the base thumbnail with this exact text: "${params.imageText}". Render it prominently in bold, 3D, highly readable YouTube thumbnail typography.` : '- Keep the visual composition but upgrade the quality.'}
      `;
    } else {
      prompt = `Create a highly engaging, clickbait-style YouTube thumbnail.
      
      --- Channel & Video Context ---
      ${params.channelNiche ? `Channel Niche: ${params.channelNiche}` : ''}
      ${params.videoType ? `Video Type: ${params.videoType}` : ''}
      ${params.title ? `Video Title/Idea: "${params.title}"` : ''}
      
      --- Design & Style ---
      Style/Vibe: ${params.style}.
      ${params.brandColors ? `Brand Colors: ${params.brandColors}` : ''}
      Background/Environment: ${params.background}.
      Main Elements/Objects: ${params.elements}.
      
      --- Character Details (if applicable) ---
      ${params.facialExpression ? `Facial Expression: ${params.facialExpression}` : ''}
      ${params.eyeExpression ? `Eye Expression: ${params.eyeExpression}` : ''}
      ${params.headShape ? `Head Shape: ${params.headShape}` : ''}
      ${params.bodyShape ? `Body Shape: ${params.bodyShape}` : ''}
      ${params.eyeColor ? `Eye Color: ${params.eyeColor}` : ''}
      ${params.emotion ? `Overall Emotion: ${params.emotion}` : ''}
      ${params.bodyPose ? `Body Pose: ${params.bodyPose}` : ''}
      
      CRITICAL INSTRUCTIONS: 
      - Aspect ratio MUST be ${parsedAspectRatio}.
      - High contrast, vibrant colors, clear focal point, extremely eye-catching.
      - If reference images are provided, use them as the main characters/subjects in the thumbnail. Pay attention to their names if specified in the prompt. Apply the Character Details (pose, expression, etc.) to them.
      - If element images are provided, incorporate those specific items into the scene.
      ${params.imageText ? `- Render this exact text prominently in the image: "${params.imageText}". Use bold, 3D, highly readable YouTube thumbnail typography.` : '- Do not output actual text/words unless it\'s a natural part of the environment. Focus on the visual storytelling.'}
      - 8k resolution, highly detailed, cinematic lighting.`;
    }

    const parts: any[] = [{ text: prompt }];
    
    // Add base thumbnail if enhancing
    if (params.baseThumbnail) {
      parts.push({ text: "\n--- Base Thumbnail to Enhance/Remix ---" });
      const base64Data = params.baseThumbnail.includes(',') ? params.baseThumbnail.split(',')[1] : params.baseThumbnail;
      parts.push({ inlineData: { mimeType: "image/png", data: base64Data } });
    }

    // Add character reference images
    if (params.referenceImages && params.referenceImages.length > 0) {
      parts.push({ text: "\n--- Reference Characters ---" });
      params.referenceImages.forEach(img => {
        parts.push({ text: `Character Name: ${img.name}` });
        const base64Data = img.dataUrl.includes(',') ? img.dataUrl.split(',')[1] : img.dataUrl;
        parts.push({ inlineData: { mimeType: "image/png", data: base64Data } });
      });
    }

    // Add element reference images
    if (params.elementImages && params.elementImages.length > 0) {
      parts.push({ text: "\n--- Reference Elements ---" });
      params.elementImages.forEach(img => {
        parts.push({ text: `Element Name: ${img.name}` });
        const base64Data = img.dataUrl.includes(',') ? img.dataUrl.split(',')[1] : img.dataUrl;
        parts.push({ inlineData: { mimeType: "image/png", data: base64Data } });
      });
    }

    try {
      const result = await ai.models.generateContent({
        model: "gemini-3-pro-image-preview",
        contents: [{ role: "user", parts }],
        config: { imageConfig: { aspectRatio: parsedAspectRatio } }
      });
      return extractImage(result);
    } catch (error: any) {
      if (isRateLimitError(error)) {
        handleCommonErrors(error, "");
      }
      if (isPermissionError(error)) {
        throw new Error("ÙØ´Ù„ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…ØµØºØ±Ø© (403). ØªØ£ÙƒØ¯ Ù…Ù† ØµÙ„Ø§Ø­ÙŠØ§Øª Ù…ÙØªØ§Ø­ API Ù„Ù†Ù…ÙˆØ°Ø¬ gemini-3-pro-image-preview.");
      }
      handleCommonErrors(error, "ÙØ´Ù„ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…ØµØºØ±Ø©.");
      throw error;
    }
  },

  // 14. Analyze Thumbnail
  async analyzeThumbnail(imageBase64: string): Promise<{
    critique: string;
    suggestedElements: string;
    suggestedText: string;
    suggestedStyle: string;
  }> {
    try {
      const ai = getAI();
      const prompt = `
        Analyze this YouTube thumbnail.
        Output a JSON object with EXACTLY these keys (values MUST be strings in Arabic):
        - critique: A brief critique of the current thumbnail.
        - suggestedElements: Specific visual elements to add (e.g., "Ø£Ø³Ù‡Ù… Ø­Ù…Ø±Ø§Ø¡ØŒ Ø¥Ø¶Ø§Ø¡Ø© Ù†ÙŠÙˆÙ†").
        - suggestedText: A short clickbait text to put on the thumbnail (e.g., "Ù„Ù† ØªØµØ¯Ù‚ Ù…Ø§ Ø­Ø¯Ø«!").
        - suggestedStyle: The overall art style (e.g., "MrBeast (Ø£Ù„ÙˆØ§Ù† ÙØ§Ù‚Ø¹Ø©ØŒ ØªØ¨Ø§ÙŠÙ† Ø¹Ø§Ù„ÙŠ)").
      `;

      const base64Data = imageBase64.includes(',') ? imageBase64.split(',')[1] : imageBase64;
      const mimeType = imageBase64.includes(',') ? imageBase64.substring(imageBase64.indexOf(':') + 1, imageBase64.indexOf(';')) : "image/jpeg";

      const result = await ai.models.generateContent({
        model: "gemini-3.1-pro-preview",
        contents: [
          {
            role: "user",
            parts: [
              { text: prompt },
              { inlineData: { mimeType: mimeType, data: base64Data } }
            ]
          }
        ],
        config: {
          responseMimeType: "application/json",
          responseSchema: {
            type: Type.OBJECT,
            properties: {
              critique: { type: Type.STRING },
              suggestedElements: { type: Type.STRING },
              suggestedText: { type: Type.STRING },
              suggestedStyle: { type: Type.STRING }
            }
          }
        }
      });

      const text = result.text || "{}";
      const jsonString = text.replace(/```json/gi, "").replace(/```/g, "").trim();
      return JSON.parse(jsonString);
    } catch (error: any) {
      console.error("Thumbnail analysis error:", error);
      // Return a fallback object instead of throwing to prevent the UI from getting stuck
      return {
        critique: "Ù„Ù… Ù†ØªÙ…ÙƒÙ† Ù…Ù† ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø¨Ø¯Ù‚Ø©ØŒ Ù„ÙƒÙ† ÙŠÙ…ÙƒÙ†Ùƒ ØªØ­Ø³ÙŠÙ†Ù‡Ø§ Ø¨Ø¥Ø¶Ø§ÙØ© Ø£Ù„ÙˆØ§Ù† Ø²Ø§Ù‡ÙŠØ© ÙˆØªØ¨Ø§ÙŠÙ† Ø¹Ø§Ù„ÙŠ.",
        suggestedElements: "Ø£Ø³Ù‡Ù… Ø­Ù…Ø±Ø§Ø¡ØŒ Ø¯ÙˆØ§Ø¦Ø± ØªØ­Ø¯ÙŠØ¯ØŒ Ø¥Ø¶Ø§Ø¡Ø© Ù†ÙŠÙˆÙ†",
        suggestedText: "Ø§Ù„Ø³Ø± Ø§Ù„Ø°ÙŠ ÙŠØ®ÙÙˆÙ†Ù‡ Ø¹Ù†Ùƒ!",
        suggestedStyle: "MrBeast (Ø£Ù„ÙˆØ§Ù† ÙØ§Ù‚Ø¹Ø©ØŒ ØªØ¨Ø§ÙŠÙ† Ø¹Ø§Ù„ÙŠØŒ ØªØ¹Ø§Ø¨ÙŠØ± Ù…Ø¨Ø§Ù„Øº ÙÙŠÙ‡Ø§)"
      };
    }
  },

  // 15. Generate Character Animation - uses referenceImages for character consistency
  async generateCharacterAnimation(params: {
    characters: {
      name: string;
      visualTraits: string;
      images: { front?: string; back?: string; closeup?: string; left?: string; right?: string; threeQuarter?: string; reference?: string; normal?: string; surreal?: string };
    }[];
    prompt: string;
    aspectRatio: "16:9" | "9:16";
    resolution?: '720p' | '1080p';
  }): Promise<string> {
    const ai = getAI();
    const { characters, prompt, aspectRatio, resolution = '1080p' } = params;

    // Collect one image per character (up to 3 total for Veo limit)
    const charImages: string[] = [];
    for (const char of characters) {
      const imgs = char.images as Record<string, string | undefined>;
      for (const value of Object.values(imgs)) {
        if (value && typeof value === 'string' && value.length > 100) {
          charImages.push(value);
          break; // one per character
        }
      }
    }
    if (charImages.length === 0) {
      throw new Error("Ù„Ø§ ØªÙˆØ¬Ø¯ ØµÙˆØ± Ù…Ø±Ø¬Ø¹ÙŠØ© ÙƒØ§ÙÙŠØ©. ÙŠØ¬Ø¨ Ø§Ù† ØªØ­ØªÙˆÙŠ Ø§Ù„Ø´Ø®ØµÙŠØ© Ø¹Ù„Ù‰ ØµÙˆØ±Ø© ÙˆØ§Ø­Ø¯Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø§Ù‚Ù„.");
    }

    // Compress images using canvas
    const compressImage = (imgBase64: string): Promise<{ data: string; mimeType: string }> => {
      return new Promise((resolve) => {
        const img = new Image();
        img.onload = () => {
          const canvas = document.createElement('canvas');
          let w = img.width, h = img.height;
          const maxDim = 1024;
          if (w > maxDim || h > maxDim) {
            const ratio = Math.min(maxDim / w, maxDim / h);
            w = Math.round(w * ratio);
            h = Math.round(h * ratio);
          }
          canvas.width = w;
          canvas.height = h;
          canvas.getContext('2d')!.drawImage(img, 0, 0, w, h);
          const dataUrl = canvas.toDataURL('image/jpeg', 0.8);
          resolve({ data: dataUrl.split(',')[1], mimeType: 'image/jpeg' });
        };
        img.onerror = () => {
          const data = imgBase64.includes(',') ? imgBase64.split(',')[1] : imgBase64;
          resolve({ data, mimeType: 'image/png' });
        };
        img.src = imgBase64.startsWith('data:') ? imgBase64 : `data:image/png;base64,${imgBase64}`;
      });
    };

    // Compress all character images
    const compressed = await Promise.all(charImages.slice(0, 3).map(compressImage));

    // Build prompt with detailed character descriptions
    const charDesc = characters.map((c, i) => {
      const label = characters.length > 1 ? `Character ${i + 1}` : 'The character';
      return `${label}: ${c.visualTraits || c.name}. MUST match the provided reference image exactly.`;
    }).join('\n');

    const sanitizedPrompt = prompt
      .replace(/Ø±Ø¹Ø¨|horror|scary/gi, 'dramatic')
      .replace(/Ø¹Ù†Ù|violence/gi, 'action')
      .replace(/Ø¯Ù…|blood/gi, 'dramatic')
      .replace(/Ù‚ØªÙ„|kill/gi, 'conflict')
      .replace(/Ù…ÙˆØª|death/gi, 'dramatic moment');

    const enhancedPrompt = `${charDesc}\n\nIMPORTANT: Each character MUST exactly match their provided reference image - same face, body, clothing, colors.\n\n${sanitizedPrompt}`;

    // Build referenceImages array for Veo 3.1
    const referenceImages = compressed.map(img => ({
      image: { imageBytes: img.data, mimeType: img.mimeType },
      referenceType: 'REFERENCE_TYPE_SUBJECT',
    }));

    // Download helper
    const downloadVideo = async (uri: string): Promise<string> => {
      const storedKey = localStorage.getItem('GEMINI_API_KEY');
      const apiKey = storedKey || process.env.GEMINI_API_KEY;
      const resp = await fetch(uri, { headers: { 'x-goog-api-key': apiKey || '' } });
      if (!resp.ok) throw new Error("ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø§Ù„Ù…ÙˆÙ„Ø¯.");
      const blob = await resp.blob();
      return new Promise((resolve, reject) => {
        const reader = new FileReader();
        reader.onloadend = () => resolve(reader.result as string);
        reader.onerror = reject;
        reader.readAsDataURL(blob);
      });
    };

    // Poll helper
    const poll = async (op: any) => {
      let count = 0;
      while (!op.done && count < 60) {
        await new Promise(r => setTimeout(r, 10000));
        op = await ai.operations.getVideosOperation({ operation: op });
        count++;
        console.log(`Poll ${count}: done=${op.done}`);
      }
      return op;
    };

    try {
      console.log(`Video gen: ${charImages.length} ref images, aspect=${aspectRatio}, res=${resolution}`);

      // Try with referenceImages first (character as reference, not start frame)
      try {
        let operation = await ai.models.generateVideos({
          model: 'veo-3.1-generate-preview',
          prompt: enhancedPrompt,
          config: {
            numberOfVideos: 1,
            referenceImages,
            resolution,
            aspectRatio,
          }
        });
        operation = await poll(operation);
        const uri = operation.response?.generatedVideos?.[0]?.video?.uri;
        if (uri) return await downloadVideo(uri);
        throw new Error("no_uri");
      } catch (refErr: any) {
        console.warn('referenceImages failed:', refErr?.message);
        // Fallback to start frame with first image only if INVALID_ARGUMENT
        if (refErr?.message?.includes('INVALID_ARGUMENT') || refErr?.message?.includes('not supported') || refErr?.message === 'no_uri') {
          console.log('Falling back to start frame approach...');
          let operation = await ai.models.generateVideos({
            model: 'veo-3.1-generate-preview',
            prompt: enhancedPrompt,
            image: { imageBytes: compressed[0].data, mimeType: compressed[0].mimeType },
            config: {
              numberOfVideos: 1,
              resolution,
              aspectRatio,
            }
          });
          operation = await poll(operation);
          const uri = operation.response?.generatedVideos?.[0]?.video?.uri;
          if (!uri) throw new Error("ØªÙ… Ø­Ø¸Ø± Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø¨Ø³Ø¨Ø¨ Ø³ÙŠØ§Ø³Ø§Øª Ø§Ù„Ø£Ù…Ø§Ù†. Ø¬Ø±Ø¨ ÙˆØµÙØ§Ù‹ Ù…Ø®ØªÙ„ÙØ§Ù‹.");
          return await downloadVideo(uri);
        }
        throw refErr;
      }

    } catch (error: any) {
      console.error('Veo error:', error);
      if (isRateLimitError(error)) handleCommonErrors(error, "");
      if (isPermissionError(error)) throw new Error("ÙØ´Ù„ Ø§Ù„ØªØ­Ø±ÙŠÙƒ (403). ØªØ£ÙƒØ¯ Ù…Ù† ØµÙ„Ø§Ø­ÙŠØ§Øª Ù…ÙØªØ§Ø­ API.");
      handleCommonErrors(error, `ÙØ´Ù„ Ø§Ù„ØªØ­Ø±ÙŠÙƒ: ${error?.message || 'Ø®Ø·Ø£ ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ'}`);
      throw error;
    }
  },

  // 15.5 Generate Video Idea from Characters (auto or enhance manual)
  async generateVideoIdeaFromCharacters(params: {
    characters: { name: string; description: string; visualTraits: string }[];
    videoType: string;
    dialogueLanguage: string;
    manualIdea?: string;
  }): Promise<{
    title: string;
    prompt: string;
    scenes: string[];
    cameraMovements: string[];
    mood: string;
    dialogueSuggestion: string;
  }> {
    const ai = getAI();
    const { characters, videoType, dialogueLanguage, manualIdea } = params;
    const charsDesc = characters.map((c, i) => `- Character ${i + 1} (${c.name}): ${c.description}. Visual: ${c.visualTraits}`).join('\n');

    const isEnhance = manualIdea && manualIdea.trim().length > 0;

    const videoTypeDirections: Record<string, string> = {
      funny: 'Comedic timing, exaggerated facial expressions, physical comedy beats, surprised reactions, comedic pauses. Light-hearted color grading with warm tones.',
      sad: 'Emotional slow movements, contemplative gazes, single tear moments, dramatic shallow depth of field. Desaturated cool color grading with blue undertones.',
      action: 'Fast dynamic movements, intense facial expressions, dramatic camera swoops, motion blur on quick actions. High-contrast color grading with teal and orange.',
      romantic: 'Soft gentle movements, warm eye contact, slow-motion hair movement, intimate close-ups. Warm golden-hour color grading with soft highlights.',
      mystery: 'Mysterious atmosphere, suspenseful slow movements, dramatic shadows, intriguing reveals. Moody cinematic grading with deep shadows and cool undertones.',
      horror: 'Mysterious atmosphere, suspenseful slow movements, dramatic shadows, intriguing reveals. Moody cinematic grading with deep shadows and cool undertones.',
      educational: 'Clear purposeful gestures, direct-to-camera address, well-lit demonstration angles. Clean bright color grading with neutral tones.',
      dramatic: 'Intense emotional performances, meaningful pauses, dramatic lighting shifts, powerful silhouettes. Rich cinematic color grading with deep shadows.',
      inspirational: 'Uplifting movements, confident posture, warm natural light, sunrise/sunset atmosphere. Warm vibrant color grading with golden highlights.',
    };

    const textPrompt = `You are an elite AI video director with expertise in Veo 3.1 prompt engineering for maximum character consistency.

CHARACTER BIBLE (these descriptions MUST be repeated exactly in the prompt):
${charsDesc}

VIDEO PARAMETERS:
- Type: ${videoType}
- Dialogue Language: ${dialogueLanguage}
- Characters will be provided as REFERENCE IMAGES to Veo 3.1's "Ingredients to Video" system

${isEnhance ? `USER'S ORIGINAL IDEA:\n"${manualIdea}"\n\nYour job: Enhance this idea into a professional Veo 3.1 prompt. Keep the core concept but make it extremely cinematic and optimized for AI video generation with perfect character consistency.` : `Generate a completely new, creative ${videoType} video idea for these characters.`}

CRITICAL PROMPT ENGINEERING RULES FOR CHARACTER CONSISTENCY:
You MUST follow the Veo 3.1 five-part formula: [Cinematography] + [Subject] + [Action] + [Context] + [Style & Audio]

1. IDENTITY ANCHORING (most important):
   - Start the prompt by describing EXACTLY what each character looks like using their visual traits
   ${characters.length > 1 ? `- For multiple characters: "The first character, a [exact visual description from bible], and the second character, a [exact visual description from bible]..."` : `- "The character, a [exact visual description from bible]..."`}
   - Include: face shape, skin tone, hair color/style/length, eye color, clothing (exact items, colors, materials), body proportions, age range
   - Add: "maintaining exact appearance as shown in the reference images"
   - NEVER use character names in the prompt - only visual descriptions

2. CINEMATOGRAPHY:
   - Specify exact lens (e.g., "35mm lens", "85mm portrait lens", "24mm wide angle")
   - Specify camera movement (e.g., "slow dolly forward", "orbiting steadicam shot", "locked tripod medium shot")
   - Specify shot type (e.g., "medium close-up", "full body wide shot", "over-the-shoulder")

3. ACTION & PERFORMANCE:
   - ${videoTypeDirections[videoType] || 'Match the mood appropriately with specific movement descriptions.'}
   - Describe micro-expressions and body language in detail

4. ENVIRONMENT & LIGHTING:
   - Describe the setting precisely (materials, colors, props, depth)
   - Specify lighting setup (e.g., "warm key light from the left, soft fill from above, practical lights in background")
   - Color grading direction

5. AUDIO & DIALOGUE:
   - If dialogue: specify voice characteristics (tone, pace, emotion) in ${dialogueLanguage}
   - Ambient sound design (e.g., "distant city traffic", "quiet room tone with clock ticking")
   - Music mood if applicable

Output a JSON object:
- "title": Catchy Arabic title for the video
- "prompt": Extremely detailed English prompt for Veo 3.1 (400+ words). MUST start with character visual description anchoring, then follow the five-part formula. Include lens, camera movement, exact lighting, environment details, action beats, and audio direction.
- "scenes": Array of 3-5 scene breakdown descriptions in Arabic
- "cameraMovements": Array of specific camera movements in Arabic with technical details
- "mood": Overall mood/atmosphere description in Arabic
- "dialogueSuggestion": Suggested dialogue lines in ${dialogueLanguage} with character emotion directions`;

    try {
      const result = await withRetry(() => ai.models.generateContent({
        model: "gemini-3.1-pro-preview",
        contents: [{ role: "user", parts: [{ text: textPrompt }] }],
        config: {
          responseMimeType: "application/json",
          responseSchema: {
            type: Type.OBJECT,
            properties: {
              title: { type: Type.STRING },
              prompt: { type: Type.STRING },
              scenes: { type: Type.ARRAY, items: { type: Type.STRING } },
              cameraMovements: { type: Type.ARRAY, items: { type: Type.STRING } },
              mood: { type: Type.STRING },
              dialogueSuggestion: { type: Type.STRING },
            },
            required: ["title", "prompt", "scenes", "cameraMovements", "mood", "dialogueSuggestion"]
          }
        }
      }));
      const text = result.text;
      if (!text) throw new Error("Ù„Ù… ÙŠØªÙ… Ø§Ø³ØªÙ„Ø§Ù… Ø±Ø¯ Ù…Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬. Ø­Ø§ÙˆÙ„ Ù…Ø±Ø© Ø§Ø®Ø±Ù‰.");
      const jsonString = text.replace(/```json\n?|\n?```/g, "").trim();
      const parsed = JSON.parse(jsonString);
      if (!parsed.prompt || !parsed.title) throw new Error("Ø§Ù„Ø±Ø¯ Ù…Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ØºÙŠØ± Ù…ÙƒØªÙ…Ù„. Ø­Ø§ÙˆÙ„ Ù…Ø±Ø© Ø§Ø®Ø±Ù‰.");
      return parsed;
    } catch (error: any) {
      if (isRateLimitError(error)) handleCommonErrors(error, "");
      if (isPermissionError(error)) throw new Error("ÙØ´Ù„ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ÙÙƒØ±Ø© (403). ØªØ§ÙƒØ¯ Ù…Ù† ØµÙ„Ø§Ø­ÙŠØ§Øª Ø§Ù„Ù…ÙØªØ§Ø­.");
      if (error instanceof SyntaxError) throw new Error("ÙØ´Ù„ ØªØ­Ù„ÙŠÙ„ Ø±Ø¯ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬. Ø­Ø§ÙˆÙ„ Ù…Ø±Ø© Ø§Ø®Ø±Ù‰.");
      handleCommonErrors(error, `ÙØ´Ù„ ØªÙˆÙ„ÙŠØ¯ ÙÙƒØ±Ø© Ø§Ù„ÙÙŠØ¯ÙŠÙˆ: ${error?.message || 'Ø®Ø·Ø£ ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ'}`);
      throw error;
    }
  },

  // 16. Generate Product Shot
  async generateProductShot(params: { product: string; background: string; lighting: string; style: string }): Promise<string> {
    const ai = getAI();
    const prompt = `High-end commercial product photography of: ${params.product}.
    Background/Environment: ${params.background}.
    Lighting: ${params.lighting}.
    Style/Vibe: ${params.style}.
    
    CRITICAL INSTRUCTIONS: 
    - This must look like a professional, award-winning advertising campaign shot.
    - Photorealistic, 8k resolution, extremely sharp focus on the product.
    - Perfect composition and color grading.`;

    try {
      const result = await ai.models.generateContent({
        model: "gemini-3-pro-image-preview",
        contents: [{ role: "user", parts: [{ text: prompt }] }],
        config: { imageConfig: { aspectRatio: "1:1" } }
      });
      return extractImage(result);
    } catch (error: any) {
      if (isRateLimitError(error)) handleCommonErrors(error, "");
      if (isPermissionError(error)) throw new Error("ÙØ´Ù„ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ±Ø© (403). ØªØ£ÙƒØ¯ Ù…Ù† ØµÙ„Ø§Ø­ÙŠØ§Øª Ù…ÙØªØ§Ø­ API.");
      handleCommonErrors(error, "ÙØ´Ù„ ØªØµÙˆÙŠØ± Ø§Ù„Ù…Ù†ØªØ¬.");
      throw error;
    }
  },

  // 17. Generate Brand Identity
  async generateBrandIdentity(description: string): Promise<{ names: string[], slogan: string, colors: string[], typography: string, moodboardImage: string }> {
    const ai = getAI();
    
    try {
      // 1. Generate Brand Strategy
      const textPrompt = `You are an expert Brand Strategist and Art Director.
      Create a brand identity concept for the following project/business: "${description}".
      
      Output a JSON object with EXACTLY these keys:
      - "names": Array of 3 creative brand name ideas (in Arabic).
      - "slogan": A catchy, short slogan (in Arabic).
      - "colors": Array of 3-4 hex color codes (e.g., ["#FF0000", "#00FF00"]) that fit the brand psychology.
      - "typography": Suggested font style description (in Arabic, e.g., "Ø®Ø· ÙƒÙˆÙÙŠ Ø­Ø¯ÙŠØ« ÙˆØ²ÙˆØ§ÙŠØ§ Ø­Ø§Ø¯Ø©").
      - "moodboardPrompt": A highly detailed image generation prompt (in English) to create an aesthetic moodboard for this brand. It should include the color palette, textures, lifestyle elements, packaging style, and overall vibe.`;

      const textResult = await ai.models.generateContent({
        model: "gemini-3.1-pro-preview",
        contents: [{ role: "user", parts: [{ text: textPrompt }] }],
        config: {
          responseMimeType: "application/json",
          responseSchema: {
            type: Type.OBJECT,
            properties: {
              names: { type: Type.ARRAY, items: { type: Type.STRING } },
              slogan: { type: Type.STRING },
              colors: { type: Type.ARRAY, items: { type: Type.STRING } },
              typography: { type: Type.STRING },
              moodboardPrompt: { type: Type.STRING }
            }
          }
        }
      });

      const text = textResult.text || "{}";
      const jsonString = text.replace(/```json\n?|\n?```/g, "").trim();
      const brandData = JSON.parse(jsonString);

      // 2. Generate Moodboard Image
      const imagePrompt = `A professional brand identity moodboard. ${brandData.moodboardPrompt}. 
      Layout: A beautiful collage of textures, color swatches, lifestyle photography, and abstract shapes representing the brand. 
      Style: Minimalist, highly aesthetic, Pinterest style, 8k resolution, photorealistic.`;
      
      const imageResult = await ai.models.generateContent({
        model: "gemini-3-pro-image-preview",
        contents: [{ role: "user", parts: [{ text: imagePrompt }] }],
        config: { imageConfig: { aspectRatio: "16:9" } }
      });
      
      const moodboardImage = extractImage(imageResult);

      return {
        names: brandData.names || ["Ø¹Ù„Ø§Ù…Ø© ØªØ¬Ø§Ø±ÙŠØ© 1", "Ø¹Ù„Ø§Ù…Ø© ØªØ¬Ø§Ø±ÙŠØ© 2"],
        slogan: brandData.slogan || "Ø´Ø¹Ø§Ø± Ù…Ù…ÙŠØ² Ù„Ø¹Ù„Ø§Ù…ØªÙƒ",
        colors: brandData.colors || ["#000000", "#FFFFFF", "#CCCCCC"],
        typography: brandData.typography || "Ø®Ø· Ø­Ø¯ÙŠØ« ÙˆØ¨Ø³ÙŠØ·",
        moodboardImage: moodboardImage
      };

    } catch (error: any) {
      if (isRateLimitError(error)) handleCommonErrors(error, "");
      if (isPermissionError(error)) throw new Error("ÙØ´Ù„ Ø§Ù„ØªÙˆÙ„ÙŠØ¯ (403). ØªØ£ÙƒØ¯ Ù…Ù† ØµÙ„Ø§Ø­ÙŠØ§Øª Ù…ÙØªØ§Ø­ API.");
      handleCommonErrors(error, "ÙØ´Ù„ Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù‡ÙˆÙŠØ© Ø§Ù„Ø¨ØµØ±ÙŠØ©.");
      throw error;
    }
  },

  // 18. Improve Ad Copy
  async improveAdCopy(topic: string, industry: string): Promise<{ largeText: string, smallText: string }> {
    const ai = getAI();
    const prompt = `Ø£Ù†Øª Ø®Ø¨ÙŠØ± ØªØ³ÙˆÙŠÙ‚ ÙˆÙƒØªØ§Ø¨Ø© Ø¥Ø¹Ù„Ø§Ù†Ø§Øª (Copywriter).
    Ù„Ø¯ÙŠ Ø¥Ø¹Ù„Ø§Ù† Ø¹Ù†: "${topic}"
    ÙÙŠ Ù…Ø¬Ø§Ù„/ØµÙ†Ø§Ø¹Ø©: "${industry}"
    
    Ø§ÙƒØªØ¨ Ù„ÙŠ:
    1. Ø¹Ù†ÙˆØ§Ù† Ø±Ø¦ÙŠØ³ÙŠ Ø¬Ø°Ø§Ø¨ ÙˆÙ‚ØµÙŠØ± Ø¬Ø¯ï¿½ï¿½Ù‹ (largeText)
    2. Ù†Øµ ÙØ±Ø¹ÙŠ Ø£Ùˆ ÙˆØµÙ Ù…Ø´ÙˆÙ‚ ÙˆÙ‚ØµÙŠï¿½ï¿½ (smallText)
    
    ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† Ø§Ù„Ø±Ø¯ Ø¨ØµÙŠØºØ© JSON ÙÙ‚Ø· ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ù…ÙØªØ§Ø­ÙŠÙ† largeText Ùˆ smallText.`;
    
    try {
      const result = await ai.models.generateContent({
        model: "gemini-3.1-pro-preview",
        contents: [{ role: "user", parts: [{ text: prompt }] }],
        config: {
          responseMimeType: "application/json",
          responseSchema: {
            type: Type.OBJECT,
            properties: {
              largeText: { type: Type.STRING },
              smallText: { type: Type.STRING }
            }
          }
        }
      });
      
      const text = result.text || "{}";
      const jsonString = text.replace(/```json/gi, "").replace(/```/g, "").trim();
      return JSON.parse(jsonString);
    } catch (error: any) {
      console.error("Copywriting error:", error);
      throw new Error("ÙØ´Ù„ ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù†Øµ Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†ÙŠ.");
    }
  },

  // 19. Generate Ad Poster
  async generateAdPoster(params: { 
    topic: string; 
    brandName: string; 
    industry?: string;
    primaryColor: string; 
    secondaryColor: string; 
    visualStyle: string;
    largeText?: string;
    smallText?: string;
    phoneNumber?: string;
    logoBase64?: string;
    elementsPosition?: string;
    language?: string;
    fontType?: string;
    textColor?: string;
    textStyle?: string;
    aspectRatio?: string;
    imageSize?: string;
    extraImageBase64?: string;
    characterImageBase64?: string;
  }): Promise<string> {
    const ai = getAI();
    let prompt = `You are an award-winning Art Director and Master Graphic Designer creating a mind-blowing, highly creative social media advertising poster.
    
    Topic/Subject of the ad: "${params.topic}".
    Brand Name: "${params.brandName}".`;
    
    if (params.industry) prompt += `\nIndustry/Niche: "${params.industry}". Think outside the box. Use clever visual metaphors, surrealism, or hyper-realistic 3D elements relevant to this industry (e.g., if it's dental, maybe a tooth shining like a diamond or a tooth acting as a washing machine; if it's internet, a turtle on a rocket skateboard).`;
    
    prompt += `\n
    Design Requirements:
    - Visual Style: ${params.visualStyle}.
    - Color Palette: Dominant primary color (${params.primaryColor}) and accent secondary color (${params.secondaryColor}). Use dramatic, studio-quality lighting (volumetric lighting, rim lights) to make the colors pop.
    - Concept: Create a striking, out-of-the-box visual metaphor or a highly engaging composition (like top-tier Behance or Pinterest ad designs).
    - Composition: Perfect social media post layout with clear visual hierarchy. Leave strategic negative space for text.
    - Quality: 8k resolution, hyper-realistic textures, flawless photo manipulation or top-tier 3D rendering, masterpiece, trending on ArtStation and Behance.`;

    if (params.largeText || params.smallText || params.phoneNumber || params.logoBase64) {
      prompt += `\n\nText and Logo Elements to include (render them clearly if possible, or leave space for them):`;
      if (params.language) prompt += `\n- Language for text: ${params.language}`;
      if (params.fontType) prompt += `\n- Typography/Font Style: ${params.fontType}`;
      if (params.textColor) prompt += `\n- Text Color: ${params.textColor}`;
      if (params.textStyle) prompt += `\n- Text Effect/Material: ${params.textStyle}`;
      if (params.elementsPosition) prompt += `\n- Preferred Position for these elements: ${params.elementsPosition}`;
      if (params.largeText) prompt += `\n- Main Headline: "${params.largeText}"`;
      if (params.smallText) prompt += `\n- Subtext/Description: "${params.smallText}"`;
      if (params.phoneNumber) prompt += `\n- Contact/Phone: "${params.phoneNumber}"`;
    } else {
      prompt += `\n\nDo not include actual readable text, just the visual composition and elements, leaving negative space for text.`;
    }

    if (params.logoBase64) {
      prompt += `\n\nIncorporate the provided logo image naturally into the design, preferably at the specified position (${params.elementsPosition || 'a suitable corner'}).`;
    }
    if (params.extraImageBase64) {
      prompt += `\n\nIncorporate the provided extra image (e.g., product, tool, or specific element) naturally into the scene.`;
    }
    if (params.characterImageBase64) {
      prompt += `\n\nIncorporate the provided character image naturally into the scene as the main actor, mascot, or presenter for the ad.`;
    }

    const parts: any[] = [{ text: prompt }];

    if (params.logoBase64) {
      const base64Data = params.logoBase64.includes(',') ? params.logoBase64.split(',')[1] : params.logoBase64;
      const mimeType = params.logoBase64.includes(',') ? params.logoBase64.substring(params.logoBase64.indexOf(':') + 1, params.logoBase64.indexOf(';')) : "image/png";
      parts.push({ inlineData: { mimeType, data: base64Data } });
    }
    if (params.extraImageBase64) {
      const base64Data = params.extraImageBase64.includes(',') ? params.extraImageBase64.split(',')[1] : params.extraImageBase64;
      const mimeType = params.extraImageBase64.includes(',') ? params.extraImageBase64.substring(params.extraImageBase64.indexOf(':') + 1, params.extraImageBase64.indexOf(';')) : "image/png";
      parts.push({ inlineData: { mimeType, data: base64Data } });
    }
    if (params.characterImageBase64) {
      const base64Data = params.characterImageBase64.includes(',') ? params.characterImageBase64.split(',')[1] : params.characterImageBase64;
      const mimeType = params.characterImageBase64.includes(',') ? params.characterImageBase64.substring(params.characterImageBase64.indexOf(':') + 1, params.characterImageBase64.indexOf(';')) : "image/png";
      parts.push({ inlineData: { mimeType, data: base64Data } });
    }

    try {
      const result = await ai.models.generateContent({
        model: "gemini-3-pro-image-preview",
        contents: [{ role: "user", parts }],
        config: { 
          imageConfig: { 
            aspectRatio: params.aspectRatio || "3:4",
            imageSize: params.imageSize || "2K"
          } 
        }
      });
      return extractImage(result);
    } catch (error: any) {
      if (isRateLimitError(error)) handleCommonErrors(error, "");
      if (isPermissionError(error)) throw new Error("ÙØ´Ù„ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¥Ø¹Ù„Ø§Ù† (403). ØªØ£ÙƒØ¯ Ù…Ù† ØµÙ„Ø§Ø­ÙŠØ§Øª Ù…ÙØªØ§Ø­ API.");
      handleCommonErrors(error, "ÙØ´Ù„ ØªØµÙ…ÙŠÙ… Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†.");
      throw error;
    }
  },

  // Character Sheet Generation - Create multiple views from a reference image
  async generateCharacterSheet(params: {
    referenceImage: string;
    characterType: 'human' | 'animal' | 'object' | 'fantasy';
    characterName: string;
    onProgress?: (progress: number) => void;
  }): Promise<{ front: string; back: string; closeup: string }> {
    const ai = getAI();
    const { referenceImage, characterType, characterName, onProgress } = params;

    const typeDescriptions: Record<string, string> = {
      human: 'a human person/child',
      animal: 'an animal/creature',
      object: 'an object/item',
      fantasy: 'a fantasy/fictional character'
    };

    const typeDesc = typeDescriptions[characterType] || 'a character';
    
    // Extract base64 from data URL
    const base64Match = referenceImage.match(/^data:image\/\w+;base64,(.+)$/);
    const imageData = base64Match ? base64Match[1] : referenceImage;
    const mimeType = referenceImage.match(/^data:(image\/\w+);/)?.[1] || 'image/jpeg';

    const results: { front: string; back: string; closeup: string } = {
      front: '',
      back: '',
      closeup: ''
    };

    // Generate Front View
    onProgress?.(10);
    console.log('Generating front view...');
    
    const frontPrompt = `Based on the reference image of ${typeDesc} named "${characterName}", generate a HIGH QUALITY full-body front view.
    
IMPORTANT REQUIREMENTS:
- EXACT same face/features as the reference image - preserve all facial details precisely
- Full body visible from head to toe
- Front-facing pose, looking at camera
- Same clothing style and colors if visible in reference
- Clean white background
- Professional photography style lighting
- High resolution, 4K quality
- Natural proportions and realistic body

The character should be instantly recognizable as the same ${typeDesc} from the reference.`;

    try {
      const frontResult = await ai.models.generateContent({
        model: "gemini-3-pro-image-preview",
        contents: [
          {
            role: "user",
            parts: [
              { inlineData: { mimeType, data: imageData } },
              { text: frontPrompt }
            ]
          }
        ],
        config: {
          responseModalities: ["image", "text"],
          temperature: 0.7,
        }
      });
      results.front = extractImage(frontResult);
      console.log('Front view generated successfully');
    } catch (error: any) {
      console.error('Front view error:', error);
      throw new Error(`ÙØ´Ù„ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£Ù…Ø§Ù…ÙŠØ©: ${error.message}`);
    }

    onProgress?.(40);

    // Generate Back View
    console.log('Generating back view...');
    
    const backPrompt = `Based on the reference image of ${typeDesc} named "${characterName}", generate a HIGH QUALITY full-body BACK view.
    
IMPORTANT REQUIREMENTS:
- Same character as the reference - same body type, hair style, clothing
- Full body visible from head to toe
- Character facing AWAY from camera (back view)
- Same clothing from the back perspective
- Clean white background
- Professional photography style lighting
- High resolution, 4K quality
- Natural proportions

Show the back of the character with consistent details (hair, clothing, body shape).`;

    try {
      const backResult = await ai.models.generateContent({
        model: "gemini-3-pro-image-preview",
        contents: [
          {
            role: "user",
            parts: [
              { inlineData: { mimeType, data: imageData } },
              { inlineData: { mimeType: 'image/png', data: results.front.split(',')[1] } },
              { text: backPrompt }
            ]
          }
        ],
        config: {
          responseModalities: ["image", "text"],
          temperature: 0.7,
        }
      });
      results.back = extractImage(backResult);
      console.log('Back view generated successfully');
    } catch (error: any) {
      console.error('Back view error:', error);
      throw new Error(`ÙØ´Ù„ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø®Ù„ÙÙŠØ©: ${error.message}`);
    }

    onProgress?.(70);

    // Generate Closeup View
    console.log('Generating closeup view...');
    
    const closeupPrompt = `Based on the reference image of ${typeDesc} named "${characterName}", generate a HIGH QUALITY closeup portrait.
    
IMPORTANT REQUIREMENTS:
- EXACT same face/features as the reference image - this is critical
- Close-up of face and upper shoulders only
- Slightly tilted or angled pose for visual interest (like looking up or 3/4 view)
- Same facial features, eyes, nose, mouth - perfectly preserved
- Clean white background
- Soft professional lighting
- High resolution, 4K quality
- Show personality in the expression

The face must be IDENTICAL to the reference - same eyes, nose, mouth, skin tone, hair.`;

    try {
      const closeupResult = await ai.models.generateContent({
        model: "gemini-3-pro-image-preview",
        contents: [
          {
            role: "user",
            parts: [
              { inlineData: { mimeType, data: imageData } },
              { inlineData: { mimeType: 'image/png', data: results.front.split(',')[1] } },
              { text: closeupPrompt }
            ]
          }
        ],
        config: {
          responseModalities: ["image", "text"],
          temperature: 0.7,
        }
      });
      results.closeup = extractImage(closeupResult);
      console.log('Closeup view generated successfully');
    } catch (error: any) {
      console.error('Closeup view error:', error);
      throw new Error(`ÙØ´Ù„ ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ±Ø© Ø§Ù„ÙˆØ¬Ù‡: ${error.message}`);
    }

    onProgress?.(100);
    return results;
  },

  // Regenerate a single view
  async regenerateCharacterView(params: {
    referenceImage: string;
    existingImages: { front: string; back: string; closeup: string };
    viewToRegenerate: 'front' | 'back' | 'closeup';
    characterType: 'human' | 'animal' | 'object' | 'fantasy';
    characterName: string;
  }): Promise<string> {
    const ai = getAI();
    const { referenceImage, existingImages, viewToRegenerate, characterType, characterName } = params;

    const typeDescriptions: Record<string, string> = {
      human: 'a human person/child',
      animal: 'an animal/creature', 
      object: 'an object/item',
      fantasy: 'a fantasy/fictional character'
    };

    const typeDesc = typeDescriptions[characterType] || 'a character';
    
    const base64Match = referenceImage.match(/^data:image\/\w+;base64,(.+)$/);
    const imageData = base64Match ? base64Match[1] : referenceImage;
    const mimeType = referenceImage.match(/^data:(image\/\w+);/)?.[1] || 'image/jpeg';

    const prompts: Record<string, string> = {
      front: `Regenerate a HIGH QUALITY full-body front view of ${typeDesc} "${characterName}". Full body, front-facing, white background, same features as reference.`,
      back: `Regenerate a HIGH QUALITY full-body back view of ${typeDesc} "${characterName}". Full body from behind, white background, same clothing and body as reference.`,
      closeup: `Regenerate a HIGH QUALITY closeup portrait of ${typeDesc} "${characterName}". Face and shoulders, slightly angled pose, white background, EXACT same facial features.`
    };

    try {
      const result = await ai.models.generateContent({
        model: "gemini-3-pro-image-preview",
        contents: [
          {
            role: "user",
            parts: [
              { inlineData: { mimeType, data: imageData } },
              { text: prompts[viewToRegenerate] }
            ]
          }
        ],
        config: {
          responseModalities: ["image", "text"],
          temperature: 0.8,
        }
      });
      return extractImage(result);
    } catch (error: any) {
      handleCommonErrors(error, "ÙØ´Ù„ Ø¥Ø¹Ø§Ø¯Ø© ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ±Ø©.");
      throw error;
    }
  }
};

